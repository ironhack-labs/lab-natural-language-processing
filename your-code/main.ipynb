{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dy/909n7xmj5_70npk7nknw102m0000gn/T/ipykernel_16326/3777615979.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Natural Language Processing\n",
    "### SMS: SPAM or HAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read Data for the Fraudulent Email Kaggle Challenge\n",
    "- Reduce the training set to speead up development. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "## Read Data for the Fraudulent Email Kaggle Challenge\n",
    "data = pd.read_csv(\"/Users/diegoalonso/Documents/Ironhack/Labs/Week_4/Day_2/lab-natural-language-processing/data/kg_train.csv\",encoding='latin-1')\n",
    "\n",
    "# Reduce the training set to speed up development. \n",
    "# Modify for final system\n",
    "data = data.head(1000)\n",
    "print(data.shape)\n",
    "data.fillna(\"\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's divide the training and test set into two partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# We´ll use data_train and data_val as it will be used on the 'Extra Features' section with this naming\n",
    "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42, stratify=data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "['here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "print(string.punctuation)\n",
    "print(stopwords.words(\"english\")[100:110])\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "snowball = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we have to clean the html code removing words\n",
    "\n",
    "- First we remove inline JavaScript/CSS\n",
    "- Then we remove html comments. This has to be done before removing regular tags since comments can contain '>' characters\n",
    "- Next we can remove the remaining tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>Dear=2C Good day hope fine=2Cdear am writting ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear=2C Good day hope fine=2Cdear am writting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>FROM MR HENRY KABORETHE CHIEF AUDITOR INCHARGE...</td>\n",
       "      <td>1</td>\n",
       "      <td>FROM MR HENRY KABORETHE CHIEF AUDITOR INCHARGE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>Will do.</td>\n",
       "      <td>0</td>\n",
       "      <td>Will do.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>FROM THE DESK OF DR.ADAMU  ISMALERAUDITING AND...</td>\n",
       "      <td>1</td>\n",
       "      <td>FROM THE DESK OF DR.ADAMU  ISMALERAUDITING AND...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>Dear Friend, My name is LOI C.ESTRADA,The wife...</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Friend, My name is LOI C.ESTRADA,The wife...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>FROM =3AMR=2ECOLLINCE ADDOATTN =3AI NEED YOUR ...</td>\n",
       "      <td>1</td>\n",
       "      <td>FROM =3AMR=2ECOLLINCE ADDOATTN =3AI NEED YOUR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>Pls send me call sheet for Equadoran--i don't ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Pls send me call sheet for Equadoran--i don't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>Yes I will arrange.</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes I will arrange.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>FYI Ã¢ÂÂ I will limit Haiti emails to major ...</td>\n",
       "      <td>0</td>\n",
       "      <td>FYI Ã¢ÂÂ I will limit Haiti emails to major ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>Mr=2E Zuhair Idris Jordan Kuwait BankCredit De...</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr=2E Zuhair Idris Jordan Kuwait BankCredit De...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label  \\\n",
       "442  Dear=2C Good day hope fine=2Cdear am writting ...      1   \n",
       "962  FROM MR HENRY KABORETHE CHIEF AUDITOR INCHARGE...      1   \n",
       "971                                           Will do.      0   \n",
       "190  FROM THE DESK OF DR.ADAMU  ISMALERAUDITING AND...      1   \n",
       "551  Dear Friend, My name is LOI C.ESTRADA,The wife...      1   \n",
       "495  FROM =3AMR=2ECOLLINCE ADDOATTN =3AI NEED YOUR ...      1   \n",
       "845  Pls send me call sheet for Equadoran--i don't ...      0   \n",
       "821                                Yes I will arrange.      0   \n",
       "409  FYI Ã¢ÂÂ I will limit Haiti emails to major ...      0   \n",
       "794  Mr=2E Zuhair Idris Jordan Kuwait BankCredit De...      1   \n",
       "\n",
       "                                     preprocessed_text  \n",
       "442  Dear=2C Good day hope fine=2Cdear am writting ...  \n",
       "962  FROM MR HENRY KABORETHE CHIEF AUDITOR INCHARGE...  \n",
       "971                                           Will do.  \n",
       "190  FROM THE DESK OF DR.ADAMU  ISMALERAUDITING AND...  \n",
       "551  Dear Friend, My name is LOI C.ESTRADA,The wife...  \n",
       "495  FROM =3AMR=2ECOLLINCE ADDOATTN =3AI NEED YOUR ...  \n",
       "845  Pls send me call sheet for Equadoran--i don't ...  \n",
       "821                                Yes I will arrange.  \n",
       "409  FYI Ã¢ÂÂ I will limit Haiti emails to major ...  \n",
       "794  Mr=2E Zuhair Idris Jordan Kuwait BankCredit De...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re #We will use regular expressions to clean the data\n",
    "\n",
    "# Function to remove inline JavaScript/CSS, HTML comments, and remaining tags\n",
    "def remove_inline_code(text):\n",
    "    # First we remove inline JavaScript\n",
    "    text = re.sub(r'<script>.*?</script>', '', text, flags=re.DOTALL)\n",
    "    # Then we must remove inline CSS\n",
    "    text = re.sub(r'<style>.*?</style>', '', text, flags=re.DOTALL)\n",
    "    # Then we remove HTML comments before removing tags\n",
    "    text = re.sub(r'<!--.*?-->', '', text, flags=re.DOTALL)\n",
    "    # Last we remove remaining tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply the function to the data \n",
    "data_train['preprocessed_text'] = data_train['text'].apply(remove_inline_code)\n",
    "data_val['preprocessed_text'] = data_val['text'].apply(remove_inline_code)\n",
    "\n",
    "# We check if the data has been cleaned correctly\n",
    "data_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove all the special characters\n",
    "    \n",
    "- Remove numbers\n",
    "    \n",
    "- Remove all single characters\n",
    " \n",
    "- Remove single characters from the start\n",
    "\n",
    "- Substitute multiple spaces with single space\n",
    "\n",
    "- Remove prefixed 'b'\n",
    "\n",
    "- Convert to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>Dear=2C Good day hope fine=2Cdear am writting ...</td>\n",
       "      <td>1</td>\n",
       "      <td>dearc good day hope finecdear am writting this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>FROM MR HENRY KABORETHE CHIEF AUDITOR INCHARGE...</td>\n",
       "      <td>1</td>\n",
       "      <td>from mr henry kaborethe chief auditor incharge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>Will do.</td>\n",
       "      <td>0</td>\n",
       "      <td>will do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>FROM THE DESK OF DR.ADAMU  ISMALERAUDITING AND...</td>\n",
       "      <td>1</td>\n",
       "      <td>from the desk of dradamu ismalerauditing and a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>Dear Friend, My name is LOI C.ESTRADA,The wife...</td>\n",
       "      <td>1</td>\n",
       "      <td>dear friend my name is loi cestradathe wife of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>FROM =3AMR=2ECOLLINCE ADDOATTN =3AI NEED YOUR ...</td>\n",
       "      <td>1</td>\n",
       "      <td>from amrecollince addoattn ai need your urgent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>Pls send me call sheet for Equadoran--i don't ...</td>\n",
       "      <td>0</td>\n",
       "      <td>pls send me call sheet for equadorani dont hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>Yes I will arrange.</td>\n",
       "      <td>0</td>\n",
       "      <td>yes will arrange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>FYI Ã¢ÂÂ I will limit Haiti emails to major ...</td>\n",
       "      <td>0</td>\n",
       "      <td>fyi will limit haiti emails to major fyi infor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>Mr=2E Zuhair Idris Jordan Kuwait BankCredit De...</td>\n",
       "      <td>1</td>\n",
       "      <td>mre zuhair idris jordan kuwait bankcredit depa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label  \\\n",
       "442  Dear=2C Good day hope fine=2Cdear am writting ...      1   \n",
       "962  FROM MR HENRY KABORETHE CHIEF AUDITOR INCHARGE...      1   \n",
       "971                                           Will do.      0   \n",
       "190  FROM THE DESK OF DR.ADAMU  ISMALERAUDITING AND...      1   \n",
       "551  Dear Friend, My name is LOI C.ESTRADA,The wife...      1   \n",
       "495  FROM =3AMR=2ECOLLINCE ADDOATTN =3AI NEED YOUR ...      1   \n",
       "845  Pls send me call sheet for Equadoran--i don't ...      0   \n",
       "821                                Yes I will arrange.      0   \n",
       "409  FYI Ã¢ÂÂ I will limit Haiti emails to major ...      0   \n",
       "794  Mr=2E Zuhair Idris Jordan Kuwait BankCredit De...      1   \n",
       "\n",
       "                                     preprocessed_text  \n",
       "442  dearc good day hope finecdear am writting this...  \n",
       "962  from mr henry kaborethe chief auditor incharge...  \n",
       "971                                            will do  \n",
       "190  from the desk of dradamu ismalerauditing and a...  \n",
       "551  dear friend my name is loi cestradathe wife of...  \n",
       "495  from amrecollince addoattn ai need your urgent...  \n",
       "845  pls send me call sheet for equadorani dont hav...  \n",
       "821                                   yes will arrange  \n",
       "409  fyi will limit haiti emails to major fyi infor...  \n",
       "794  mre zuhair idris jordan kuwait bankcredit depa...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to preprocess text\n",
    "def remove_and_convert(text):\n",
    "    # Remove all special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d', '', text)\n",
    "    \n",
    "    # Remove all single characters\n",
    "    text = re.sub(r'\\b\\w\\b', '', text)\n",
    "    \n",
    "    # Remove single characters from the start\n",
    "    text = re.sub(r'^\\w\\s', '', text)\n",
    "    \n",
    "    # Substitute multiple spaces with single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove prefixed 'b'\n",
    "    text = re.sub(r'^b', '', text)\n",
    "    \n",
    "    # Convert to Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply the function to the data \n",
    "data_train['preprocessed_text'] = data_train['preprocessed_text'].apply(remove_and_convert)\n",
    "data_val['preprocessed_text'] = data_val['text'].apply(remove_and_convert)\n",
    "\n",
    "# We check if the data has been cleaned correctly\n",
    "data_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Now let's work on removing stopwords\n",
    "Remove the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>Dear=2C Good day hope fine=2Cdear am writting ...</td>\n",
       "      <td>1</td>\n",
       "      <td>dearc good day hope finecdear writting mail du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>FROM MR HENRY KABORETHE CHIEF AUDITOR INCHARGE...</td>\n",
       "      <td>1</td>\n",
       "      <td>mr henry kaborethe chief auditor inchargeforei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>Will do.</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>FROM THE DESK OF DR.ADAMU  ISMALERAUDITING AND...</td>\n",
       "      <td>1</td>\n",
       "      <td>desk dradamu ismalerauditing accounting manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>Dear Friend, My name is LOI C.ESTRADA,The wife...</td>\n",
       "      <td>1</td>\n",
       "      <td>dear friend name loi cestradathe wife mr josep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>FROM =3AMR=2ECOLLINCE ADDOATTN =3AI NEED YOUR ...</td>\n",
       "      <td>1</td>\n",
       "      <td>amrecollince addoattn ai need urgent assistanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>Pls send me call sheet for Equadoran--i don't ...</td>\n",
       "      <td>0</td>\n",
       "      <td>pls send call sheet equadorani dont clue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>Yes I will arrange.</td>\n",
       "      <td>0</td>\n",
       "      <td>yes arrange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>FYI Ã¢ÂÂ I will limit Haiti emails to major ...</td>\n",
       "      <td>0</td>\n",
       "      <td>fyi limit haiti emails major fyi information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>Mr=2E Zuhair Idris Jordan Kuwait BankCredit De...</td>\n",
       "      <td>1</td>\n",
       "      <td>mre zuhair idris jordan kuwait bankcredit depa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label  \\\n",
       "442  Dear=2C Good day hope fine=2Cdear am writting ...      1   \n",
       "962  FROM MR HENRY KABORETHE CHIEF AUDITOR INCHARGE...      1   \n",
       "971                                           Will do.      0   \n",
       "190  FROM THE DESK OF DR.ADAMU  ISMALERAUDITING AND...      1   \n",
       "551  Dear Friend, My name is LOI C.ESTRADA,The wife...      1   \n",
       "495  FROM =3AMR=2ECOLLINCE ADDOATTN =3AI NEED YOUR ...      1   \n",
       "845  Pls send me call sheet for Equadoran--i don't ...      0   \n",
       "821                                Yes I will arrange.      0   \n",
       "409  FYI Ã¢ÂÂ I will limit Haiti emails to major ...      0   \n",
       "794  Mr=2E Zuhair Idris Jordan Kuwait BankCredit De...      1   \n",
       "\n",
       "                                     preprocessed_text  \n",
       "442  dearc good day hope finecdear writting mail du...  \n",
       "962  mr henry kaborethe chief auditor inchargeforei...  \n",
       "971                                                     \n",
       "190  desk dradamu ismalerauditing accounting manage...  \n",
       "551  dear friend name loi cestradathe wife mr josep...  \n",
       "495  amrecollince addoattn ai need urgent assistanc...  \n",
       "845           pls send call sheet equadorani dont clue  \n",
       "821                                        yes arrange  \n",
       "409       fyi limit haiti emails major fyi information  \n",
       "794  mre zuhair idris jordan kuwait bankcredit depa...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply the function to the data\n",
    "data_train['preprocessed_text'] = data_train['preprocessed_text'].apply(remove_stopwords)\n",
    "data_val['preprocessed_text'] = data_val['preprocessed_text'].apply(remove_stopwords)  \n",
    "\n",
    "data_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tame Your Text with Lemmatization\n",
    "Break sentences into words, then use lemmatization to reduce them to their base form (e.g., \"running\" becomes \"run\"). See how this creates cleaner data for analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>Dear=2C Good day hope fine=2Cdear am writting ...</td>\n",
       "      <td>1</td>\n",
       "      <td>dearc good day hope finecdear writting mail du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>FROM MR HENRY KABORETHE CHIEF AUDITOR INCHARGE...</td>\n",
       "      <td>1</td>\n",
       "      <td>mr henry kaborethe chief auditor inchargeforei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>Will do.</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>FROM THE DESK OF DR.ADAMU  ISMALERAUDITING AND...</td>\n",
       "      <td>1</td>\n",
       "      <td>desk dradamu ismalerauditing accounting manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>Dear Friend, My name is LOI C.ESTRADA,The wife...</td>\n",
       "      <td>1</td>\n",
       "      <td>dear friend name loi cestradathe wife mr josep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>FROM =3AMR=2ECOLLINCE ADDOATTN =3AI NEED YOUR ...</td>\n",
       "      <td>1</td>\n",
       "      <td>amrecollince addoattn ai need urgent assistanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>Pls send me call sheet for Equadoran--i don't ...</td>\n",
       "      <td>0</td>\n",
       "      <td>pls send call sheet equadorani dont clue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>Yes I will arrange.</td>\n",
       "      <td>0</td>\n",
       "      <td>yes arrange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>FYI Ã¢ÂÂ I will limit Haiti emails to major ...</td>\n",
       "      <td>0</td>\n",
       "      <td>fyi limit haiti email major fyi information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>Mr=2E Zuhair Idris Jordan Kuwait BankCredit De...</td>\n",
       "      <td>1</td>\n",
       "      <td>mre zuhair idris jordan kuwait bankcredit depa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label  \\\n",
       "442  Dear=2C Good day hope fine=2Cdear am writting ...      1   \n",
       "962  FROM MR HENRY KABORETHE CHIEF AUDITOR INCHARGE...      1   \n",
       "971                                           Will do.      0   \n",
       "190  FROM THE DESK OF DR.ADAMU  ISMALERAUDITING AND...      1   \n",
       "551  Dear Friend, My name is LOI C.ESTRADA,The wife...      1   \n",
       "495  FROM =3AMR=2ECOLLINCE ADDOATTN =3AI NEED YOUR ...      1   \n",
       "845  Pls send me call sheet for Equadoran--i don't ...      0   \n",
       "821                                Yes I will arrange.      0   \n",
       "409  FYI Ã¢ÂÂ I will limit Haiti emails to major ...      0   \n",
       "794  Mr=2E Zuhair Idris Jordan Kuwait BankCredit De...      1   \n",
       "\n",
       "                                     preprocessed_text  \n",
       "442  dearc good day hope finecdear writting mail du...  \n",
       "962  mr henry kaborethe chief auditor inchargeforei...  \n",
       "971                                                     \n",
       "190  desk dradamu ismalerauditing accounting manage...  \n",
       "551  dear friend name loi cestradathe wife mr josep...  \n",
       "495  amrecollince addoattn ai need urgent assistanc...  \n",
       "845           pls send call sheet equadorani dont clue  \n",
       "821                                        yes arrange  \n",
       "409        fyi limit haiti email major fyi information  \n",
       "794  mre zuhair idris jordan kuwait bankcredit depa...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Function to lemmatize and tokenize\n",
    "def tokenize_and_lemmatize(text):\n",
    "    # Check if the input is a list\n",
    "    if isinstance(text, list):\n",
    "        # If it's a list, join the words back into a string\n",
    "        text = ' '.join(text)\n",
    "    \n",
    "    # Tokenize the text into individual words\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Create a lemmatizer object\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Lemmatize each token and return the result\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # Join the lemmatized tokens back into a string\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Apply the function to the data\n",
    "data_train['preprocessed_text'] = data_train['preprocessed_text'].apply(tokenize_and_lemmatize)\n",
    "data_val['preprocessed_text'] = data_val['preprocessed_text'].apply(tokenize_and_lemmatize)\n",
    "\n",
    "data_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of Words\n",
    "Let's get the 10 top words in ham and spam messages (**EXPLORATORY DATA ANALYSIS**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words in ham messages:\n",
      "the: 1433\n",
      "to: 912\n",
      "and: 690\n",
      "of: 682\n",
      "a: 532\n",
      "in: 483\n",
      "that: 338\n",
      "for: 318\n",
      "is: 302\n",
      "on: 253\n",
      "\n",
      "Top 10 words in spam messages:\n",
      "the: 4654\n",
      "to: 3741\n",
      "of: 3373\n",
      "and: 2618\n",
      "in: 2162\n",
      "I: 1990\n",
      "you: 1838\n",
      "this: 1588\n",
      "a: 1556\n",
      "your: 1352\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Split the data into ham and spam messages\n",
    "ham_messages = data_train[data_train['label'] == 0]['text']\n",
    "spam_messages = data_train[data_train['label'] == 1]['text']\n",
    "\n",
    "# Count the frequency of each word in the ham messages\n",
    "ham_words = Counter(' '.join(ham_messages).split())\n",
    "\n",
    "# Count the frequency of each word in the spam messages\n",
    "spam_words = Counter(' '.join(spam_messages).split())\n",
    "\n",
    "# Get the top 10 words in the ham messages\n",
    "top_ham_words = ham_words.most_common(10)\n",
    "\n",
    "# Get the top 10 words in the spam messages\n",
    "top_spam_words = spam_words.most_common(10)\n",
    "\n",
    "# Print the results\n",
    "print(\"Top 10 words in ham messages:\")\n",
    "for word, count in top_ham_words:\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "print(\"\\nTop 10 words in spam messages:\")\n",
    "for word, count in top_spam_words:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>money_mark</th>\n",
       "      <th>suspicious_words</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>Dear=2C Good day hope fine=2Cdear am writting ...</td>\n",
       "      <td>1</td>\n",
       "      <td>dearc good day hope finecdear writting mail du...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>FROM MR HENRY KABORETHE CHIEF AUDITOR INCHARGE...</td>\n",
       "      <td>1</td>\n",
       "      <td>mr henry kaborethe chief auditor inchargeforei...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>Will do.</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>FROM THE DESK OF DR.ADAMU  ISMALERAUDITING AND...</td>\n",
       "      <td>1</td>\n",
       "      <td>desk dradamu ismalerauditing accounting manage...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>Dear Friend, My name is LOI C.ESTRADA,The wife...</td>\n",
       "      <td>1</td>\n",
       "      <td>dear friend name loi cestradathe wife mr josep...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label  \\\n",
       "442  Dear=2C Good day hope fine=2Cdear am writting ...      1   \n",
       "962  FROM MR HENRY KABORETHE CHIEF AUDITOR INCHARGE...      1   \n",
       "971                                           Will do.      0   \n",
       "190  FROM THE DESK OF DR.ADAMU  ISMALERAUDITING AND...      1   \n",
       "551  Dear Friend, My name is LOI C.ESTRADA,The wife...      1   \n",
       "\n",
       "                                     preprocessed_text  money_mark  \\\n",
       "442  dearc good day hope finecdear writting mail du...           1   \n",
       "962  mr henry kaborethe chief auditor inchargeforei...           1   \n",
       "971                                                              1   \n",
       "190  desk dradamu ismalerauditing accounting manage...           1   \n",
       "551  dear friend name loi cestradathe wife mr josep...           1   \n",
       "\n",
       "     suspicious_words  text_len  \n",
       "442                 1      1024  \n",
       "962                 1      1954  \n",
       "971                 0         0  \n",
       "190                 1       390  \n",
       "551                 1      1507  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We add to the original dataframe two additional indicators (money symbols and suspicious words).\n",
    "money_simbol_list = \"|\".join([\"euro\",\"dollar\",\"pound\",\"€\",\"$\"])\n",
    "suspicious_words = \"|\".join([\"free\",\"cheap\",\"sex\",\"money\",\"account\",\"bank\",\"fund\",\"transfer\",\"transaction\",\"win\",\"deposit\",\"password\"])\n",
    "\n",
    "data_train['money_mark'] = data_train['preprocessed_text'].str.contains(money_simbol_list)*1\n",
    "data_train['suspicious_words'] = data_train['preprocessed_text'].str.contains(suspicious_words)*1\n",
    "data_train['text_len'] = data_train['preprocessed_text'].apply(lambda x: len(x)) \n",
    "\n",
    "data_val['money_mark'] = data_val['preprocessed_text'].str.contains(money_simbol_list)*1\n",
    "data_val['suspicious_words'] = data_val['preprocessed_text'].str.contains(suspicious_words)*1\n",
    "data_val['text_len'] = data_val['preprocessed_text'].apply(lambda x: len(x)) \n",
    "\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How would work the Bag of Words with Count Vectorizer concept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dearc good day hope finecdear writting mail due respect heartful tear since known met previously asking assistanceci glad render assistance situation nowe make proposal well known given opportunitye would like use opportunity introduce youe miss johana johnpaul year old girl liberia cthe daughter late godwin johnpaul deputy minister national security leadership president charles taylor liberia exile many innocent soul killede father killed government charlestaylorcheaccuse father coup attempt month mother cynthia also killede main reason contacting seek assistance area future investment also want hand huge amount money youe money ten millon five hundred thousand u dollar deposited year ago father made sole beneficiaryfnext kin moneye asking stand behalf make claim bankcam girl young age cannt handle transactionci want stand foregin partner oversea also help investment money well send telephone number picture okeeee original copy document concering money herecso please expecting hear soone regardsc miss johana\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# To make Bag of Words work with Coubt Vectorizer, we will have to combine the messages so that we can convert it to a vector so that we can apply the it to a classifier.\n",
    "# We will join every message in a link them with blank spaces. \".iloc\" is Purely integer-location based indexing for selection by position. \n",
    "\n",
    "messages = []\n",
    "for row in range(0,len(data_train.index)):\n",
    "    messages.append(str(data_train['preprocessed_text'].iloc[row]))\n",
    "\n",
    "print (messages [0])\n",
    "\n",
    "# implement BAG OF WORDS\n",
    "countvector=CountVectorizer(ngram_range=(1,2))\n",
    "traindataset=countvector.fit_transform(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TD-IDF\n",
    "\n",
    "- Load the vectorizer\n",
    "\n",
    "- Vectorize all dataset\n",
    "\n",
    "- print the shape of the vetorized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 17179)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Create a CountVectorizer object for TF-IDF\n",
    "tfidfvector = TfidfVectorizer()\n",
    "\n",
    "# Vectorize the messages dataset\n",
    "vectorized_messages = tfidfvector.fit_transform(messages)\n",
    "\n",
    "# Print the shape of the vectorized messages\n",
    "print(vectorized_messages.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And the Train a Classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Fit the Naive Bayes model\n",
    "naive=MultinomialNB()\n",
    "naive.fit(traindataset,data_train['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Task - Implement a SPAM/HAM classifier\n",
    "\n",
    "https://www.kaggle.com/t/b384e34013d54d238490103bc3c360ce\n",
    "\n",
    "The classifier can not be changed!!! It must be the MultinimialNB with default parameters!\n",
    "\n",
    "Your task is to find the **best feature representation**.\n",
    "\n",
    "You can work with teams of two persons (recommended)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extraction Method: TF-IDF\n",
      "[[74 15]\n",
      " [ 6 65]]\n",
      "The accuracy score is: 0.86875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.83      0.88        89\n",
      "           1       0.81      0.92      0.86        71\n",
      "\n",
      "    accuracy                           0.87       160\n",
      "   macro avg       0.87      0.87      0.87       160\n",
      "weighted avg       0.88      0.87      0.87       160\n",
      "\n",
      "Feature Extraction Method: CountVectorizer\n",
      "[[79 10]\n",
      " [ 6 65]]\n",
      "The accuracy score is: 0.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91        89\n",
      "           1       0.87      0.92      0.89        71\n",
      "\n",
      "    accuracy                           0.90       160\n",
      "   macro avg       0.90      0.90      0.90       160\n",
      "weighted avg       0.90      0.90      0.90       160\n",
      "\n",
      "Feature Extraction Method: TF-IDF (ngram_range=(1,2))\n",
      "[[74 15]\n",
      " [ 6 65]]\n",
      "The accuracy score is: 0.86875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.83      0.88        89\n",
      "           1       0.81      0.92      0.86        71\n",
      "\n",
      "    accuracy                           0.87       160\n",
      "   macro avg       0.87      0.87      0.87       160\n",
      "weighted avg       0.88      0.87      0.87       160\n",
      "\n",
      "Feature Extraction Method: CountVectorizer (ngram_range=(1,2))\n",
      "[[71 18]\n",
      " [ 6 65]]\n",
      "The accuracy score is: 0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.86        89\n",
      "           1       0.78      0.92      0.84        71\n",
      "\n",
      "    accuracy                           0.85       160\n",
      "   macro avg       0.85      0.86      0.85       160\n",
      "weighted avg       0.86      0.85      0.85       160\n",
      "\n",
      "Feature Extraction Method: TF-IDF (ngram_range=(2,2))\n",
      "[[89  0]\n",
      " [12 59]]\n",
      "The accuracy score is: 0.925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94        89\n",
      "           1       1.00      0.83      0.91        71\n",
      "\n",
      "    accuracy                           0.93       160\n",
      "   macro avg       0.94      0.92      0.92       160\n",
      "weighted avg       0.93      0.93      0.92       160\n",
      "\n",
      "Feature Extraction Method: CountVectorizer (ngram_range=(2,2))\n",
      "[[86  3]\n",
      " [10 61]]\n",
      "The accuracy score is: 0.91875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93        89\n",
      "           1       0.95      0.86      0.90        71\n",
      "\n",
      "    accuracy                           0.92       160\n",
      "   macro avg       0.92      0.91      0.92       160\n",
      "weighted avg       0.92      0.92      0.92       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_train['preprocessed_text'], data_train['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the classifier\n",
    "clf = naive\n",
    "\n",
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "y_pred = clf.predict(X_test_vectorized)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Feature Extraction Method: TF-IDF\")\n",
    "matrix=confusion_matrix(y_test, y_pred)\n",
    "print(matrix) # print confusion matrix\n",
    "score=accuracy_score(y_test, y_pred)\n",
    "print(f'The accuracy score is: {score}') # print(score)\n",
    "report=classification_report(y_test, y_pred)\n",
    "print(report) # print report\n",
    "\n",
    "# CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "y_pred = clf.predict(X_test_vectorized)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Feature Extraction Method: CountVectorizer\")\n",
    "matrix=confusion_matrix(y_test, y_pred)\n",
    "print(matrix)\n",
    "score=accuracy_score(y_test, y_pred)\n",
    "print(f'The accuracy score is: {score}')\n",
    "report=classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# TF-IDF (ngram_range=(1,2))\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "y_pred = clf.predict(X_test_vectorized)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Feature Extraction Method: TF-IDF (ngram_range=(1,2))\")\n",
    "matrix=confusion_matrix(y_test, y_pred)\n",
    "print(matrix)\n",
    "score=accuracy_score(y_test, y_pred)\n",
    "print(f'The accuracy score is: {score}')\n",
    "report=classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# CountVectorizer (ngram_range=(1,2))\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "y_pred = clf.predict(X_test_vectorized)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Feature Extraction Method: CountVectorizer (ngram_range=(1,2))\")\n",
    "matrix=confusion_matrix(y_test, y_pred)\n",
    "print(matrix)\n",
    "score=accuracy_score(y_test, y_pred)\n",
    "print(f'The accuracy score is: {score}')\n",
    "report=classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# TF-IDF (ngram_range=(2,2))\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,2))\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "y_pred = clf.predict(X_test_vectorized)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Feature Extraction Method: TF-IDF (ngram_range=(2,2))\")\n",
    "matrix=confusion_matrix(y_test, y_pred)\n",
    "print(matrix)\n",
    "score=accuracy_score(y_test, y_pred)\n",
    "print(f'The accuracy score is: {score}')\n",
    "report=classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# CountVectorizer (ngram_range=(2,2))\n",
    "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "clf.fit(X_train_vectorized, y_train)\n",
    "y_pred = clf.predict(X_test_vectorized)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Feature Extraction Method: CountVectorizer (ngram_range=(2,2))\")\n",
    "matrix=confusion_matrix(y_test, y_pred)\n",
    "print(matrix)\n",
    "score=accuracy_score(y_test, y_pred)\n",
    "print(f'The accuracy score is: {score}')\n",
    "report=classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two best classifiers are TF-IDF and CountVectorizer with ngram_range=(2,2)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
