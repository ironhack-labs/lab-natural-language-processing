{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "BxGnYy2c4yRj",
        "outputId": "fabf73c4-cced-4dc5-fb98-990f8843fe23"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XI9WkEXr4yRk"
      },
      "source": [
        "# Lab | Natural Language Processing\n",
        "### SMS: SPAM or HAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5asjEIE4yRk"
      },
      "source": [
        "### Let's prepare the environment"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk scikit-learn pandas matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTE6wXM-GhCM",
        "outputId": "fe1053d1-d129-4a29-81af-971901bc3bc3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "rgyGM4fK4yRl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk import pos_tag"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_Nm1YXh4yRl"
      },
      "source": [
        "- Read Data for the Fraudulent Email Kaggle Challenge\n",
        "- Reduce the training set to speead up development."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "url_test = \"https://raw.githubusercontent.com/KJanzon/lab-natural-language-processing/refs/heads/main/data/kg_test.csv\"\n",
        "url_train = \"https://raw.githubusercontent.com/KJanzon/lab-natural-language-processing/refs/heads/main/data/kg_train.csv\"\n"
      ],
      "metadata": {
        "id": "kdSt3V_778fz"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3iXz34r4yRl",
        "outputId": "b673b202-0840-48e9-deea-a7eb7bd98718"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 2)\n",
            "<bound method NDFrame.head of                                                   text  label\n",
            "0    DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...      1\n",
            "1                                             Will do.      0\n",
            "2    Nora--Cheryl has emailed dozens of memos about...      0\n",
            "3    Dear Sir=2FMadam=2C I know that this proposal ...      1\n",
            "4                                                  fyi      0\n",
            "..                                                 ...    ...\n",
            "995  So what's the latest? It sounds contradictory ...      0\n",
            "996  TRANSFER OF 36,759,000.00 MILLION POUNDS TO YO...      1\n",
            "997  Barb I will call to explain. Are you back in t...      0\n",
            "998    Yang on travelNot free tonite.May work tomorrow      0\n",
            "999  sbwhoeopSunday February 21 2010 7:42 PMHShaunH...      0\n",
            "\n",
            "[1000 rows x 2 columns]>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-128-c6cb4fc71a28>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  train_data.fillna(\"\",inplace=True)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "## Read Data for the Fraudulent Email Kaggle Challenge\n",
        "train_data = pd.read_csv(url_train)\n",
        "test_data = pd.read_csv(url_test)\n",
        "\n",
        "# Reduce the training set to speed up development.\n",
        "# Modify for final system\n",
        "train_data = train_data.head(1000)\n",
        "print(train_data.shape)\n",
        "train_data.fillna(\"\",inplace=True)\n",
        "print(train_data.head)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code# Ensuring the dataset has the expected structure\n",
        "if \"text\" in train_data.columns and \"label\" in train_data.columns:\n",
        "    X = train_data[\"text\"]  # Features (SMS messages)\n",
        "    y = train_data[\"label\"]  # Labels (Spam or Ham)\n",
        "else:\n",
        "    X = train_data.iloc[:, 0]  # Assuming first column is text\n",
        "    y = train_data.iloc[:, 1]  # Assuming second column is label\n"
      ],
      "metadata": {
        "id": "e6BkS0CUgjHd"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK datasets\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEeETKVNGVsl",
        "outputId": "b7cdb548-9a32-48a7-9e1b-b481a17b36f3"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmtVg89e4yRl"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "LNzmgIrj4yRm"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_html(text):\n",
        "    # Remove inline JavaScript & CSS\n",
        "    text = re.sub(r'<script.*?</script>', '', text, flags=re.DOTALL)  # Remove JavaScript\n",
        "    text = re.sub(r'<style.*?</style>', '', text, flags=re.DOTALL)  # Remove CSS\n",
        "\n",
        "    # Remove HTML comments\n",
        "    text = re.sub(r'<!--.*?-->', '', text, flags=re.DOTALL)\n",
        "\n",
        "    # Remove remaining HTML tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvOsnHmS4yRm"
      },
      "source": [
        "## Now, we have to clean the html code removing words\n",
        "\n",
        "- First we remove inline JavaScript/CSS\n",
        "- Then we remove html comments. This has to be done before removing regular tags since comments can contain '>' characters\n",
        "- Next we can remove the remaining tags"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_vLhNIi4yRm"
      },
      "source": [
        "- Remove all the special characters\n",
        "    \n",
        "- Remove numbers\n",
        "    \n",
        "- Remove all single characters\n",
        "\n",
        "- Remove single characters from the start\n",
        "\n",
        "- Substitute multiple spaces with single space\n",
        "\n",
        "- Remove prefixed 'b'\n",
        "\n",
        "- Convert to Lowercase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "mMq1ey5Q4yRm"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    import re\n",
        "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Keep only letters and spaces\n",
        "    text = re.sub(r'\\b\\d+\\b', '', text)  # Remove standalone numbers\n",
        "    text = re.sub(r'\\d+', '', text)  # Remove numbers inside words\n",
        "    text = re.sub(r'\\b[a-zA-Z]\\b', '', text)  # Remove single characters\n",
        "    text = re.sub(r'\\b\\w{20,}\\b', '', text)  # Remove long words (20+ chars)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text.lower()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNmslj7c4yRm"
      },
      "source": [
        "## Now let's work on removing stopwords\n",
        "Remove the stopwords."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "1ISk3RGb4yRm"
      },
      "outputs": [],
      "source": [
        "# Load English stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Manually add unwanted words\n",
        "custom_stopwords = {\"u\", \"pm\", \"mr\", \"percent\"}\n",
        "stop_words.update(custom_stopwords)  # Add to stopword set\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    return ' '.join([word for word in text.split() if word not in stop_words])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljOq9jLD4yRm"
      },
      "source": [
        "## Tame Your Text with Lemmatization\n",
        "Break sentences into words, then use lemmatization to reduce them to their base form (e.g., \"running\" becomes \"run\"). See how this creates cleaner data for analysis!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "rnlKkdYF4yRm"
      },
      "outputs": [],
      "source": [
        "# Initialize lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    # Tokenize the text into words\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # Apply lemmatization\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "    # Join words back into a sentence\n",
        "    return ' '.join(lemmatized_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69JXvloT4yRl"
      },
      "source": [
        "### Let's divide the training and test set into two partitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td1oO-Tf4yRl",
        "outputId": "79ab80a0-358f-4976-e286-b7cebcaa851a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 800\n",
            "Testing set size: 200\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Apply text preprocessing BEFORE splitting\n",
        "X_cleaned = X.apply(clean_html)          # Remove HTML\n",
        "X_cleaned = X_cleaned.apply(clean_text)   # Remove special characters, numbers, etc.\n",
        "X_cleaned = X_cleaned.apply(remove_stopwords) # Remove stopwords\n",
        "X_cleaned = X_cleaned.apply(lemmatize_text)   # Apply Lemmatization\n",
        "\n",
        "\n",
        "    # Split dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display dataset partition sizes\n",
        "print(f\"Training set size: {len(X_train)}\")\n",
        "print(f\"Testing set size: {len(X_test)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"before\", X.head())\n",
        "\n",
        "print(\"after\", X_train.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh7YLyy3jGj3",
        "outputId": "772f2778-e3b7-4006-a929-197926533ebc"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before 0    DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...\n",
            "1                                             Will do.\n",
            "2    Nora--Cheryl has emailed dozens of memos about...\n",
            "3    Dear Sir=2FMadam=2C I know that this proposal ...\n",
            "4                                                  fyi\n",
            "Name: text, dtype: object\n",
            "after 29         regard nelson smithkindly reply private email\n",
            "535           able reach oscar supposed send pdb receive\n",
            "695    huma abedin bim checking pat work jack jake re...\n",
            "557                          announced monday cant today\n",
            "836    bank africaagence san pedro bp san pedro cote ...\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEN0Rsmw4yRl",
        "outputId": "cc1fbcca-214a-4fa5-8bbd-67785001981f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "['needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on']\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "print(string.punctuation)\n",
        "print(stopwords.words(\"english\")[100:110])\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "snowball = SnowballStemmer('english')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbpjyH1c4yRm"
      },
      "source": [
        "## Bag Of Words\n",
        "Let's get the 10 top words in ham and spam messages (**EXPLORATORY DATA ANALYSIS**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBSvnSid4yRm",
        "outputId": "39858502-1b20-4cb6-8d63-3595f3d6190c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Top Ham Words  Ham Count Top Spam Words  Spam Count\n",
            "0         would         93          money         795\n",
            "1         state         92        account         662\n",
            "2     president         84           bank         606\n",
            "3          call         73           fund         565\n",
            "4     secretary         71       business         393\n",
            "5          time         70    transaction         347\n",
            "6          work         63        country         337\n",
            "7           one         63       transfer         326\n",
            "8          said         59        company         318\n",
            "9      american         58        million         315\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "# Separate ham and spam messages\n",
        "ham_messages = X_train[y_train == 0]  # Ham (Non-spam)\n",
        "spam_messages = X_train[y_train == 1]  # Spam\n",
        "\n",
        "# Function to get top N words, excluding stopwords\n",
        "def get_top_words(messages, n=10):\n",
        "    all_words = ' '.join(messages).split()  # Merge all messages and split into words\n",
        "    filtered_words = [word for word in all_words if word.lower() not in stop_words]  # Remove stopwords\n",
        "    word_counts = Counter(filtered_words)  # Count word frequencies\n",
        "    return word_counts.most_common(n)  # Get top n words\n",
        "\n",
        "# Get top 10 words in ham and spam messages\n",
        "top_ham_words = get_top_words(ham_messages, 10)\n",
        "top_spam_words = get_top_words(spam_messages, 10)\n",
        "\n",
        "# Convert to DataFrame for better visualization\n",
        "df_top_words = pd.DataFrame({\n",
        "    \"Top Ham Words\": [word[0] for word in top_ham_words],\n",
        "    \"Ham Count\": [word[1] for word in top_ham_words],\n",
        "    \"Top Spam Words\": [word[0] for word in top_spam_words],\n",
        "    \"Spam Count\": [word[1] for word in top_spam_words]\n",
        "})\n",
        "\n",
        "# Display results\n",
        "print(df_top_words.head(10))  # Display the top 10 words in both categories"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find all ham (non-spam) messages that contain the word \"president\"\n",
        "ham_with_president = X_cleaned[(y_train == 0) & (X_cleaned.str.contains(r'\\bpresident\\b', case=False, na=False))]\n",
        "\n",
        "# Display the first few results\n",
        "print(\"Ham Messages Containing 'President':\")\n",
        "print(ham_with_president.head(10))  # Show first 10 messages\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-hY0rz8v6Z5",
        "outputId": "089a73c4-138c-4451-bdf0-7d83b5cd88ce"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ham Messages Containing 'President':\n",
            "64     sbwhoeopwednesday september amhh fyi midterm s...\n",
            "112    madame secretary forgive email wanted thank pr...\n",
            "189    interest hague latest briefing hostile tony to...\n",
            "191    good morning cheryl trying reach followup week...\n",
            "242    sbwhoeopmonday november pmhfyi chance wm hague...\n",
            "269    spanish fm moratinos requested speak today tom...\n",
            "304    attached enclosed demarche letter went reflect...\n",
            "326    httpwwwnybookscomarticlesarchivesdecbitterneww...\n",
            "372    depart private residence en route white house ...\n",
            "391    apparently cant get away sharing ft oped page ...\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PFwqF8rwsVwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure text preprocessing is applied\n",
        "train_data[\"preprocessed_text\"] = train_data[\"text\"].apply(clean_text)\n",
        "test_data[\"preprocessed_text\"] = test_data[\"text\"].apply(clean_text)"
      ],
      "metadata": {
        "id": "TD7nRHLM2UBL"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joDnk4Kz4yRm"
      },
      "source": [
        "## Extra features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uxFg4w1N4yRm",
        "outputId": "0b9ea053-23c4-4c3d-dafc-2d2677a6b2c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  usiness is for the fact that the deceased man ...   \n",
              "1  They are happy to adjust to the afternoon. I a...   \n",
              "2  Lael Brainard was confirmed 78-19 this afterno...   \n",
              "3  H <hrod17@clintonemail.com>Friday March 26 201...   \n",
              "4  n;\"> Dear Good Friend,<br><br><br>I am happy t...   \n",
              "\n",
              "                                   preprocessed_text  money_mark  \\\n",
              "0  usiness is for the fact that the deceased man ...           1   \n",
              "1  they are happy to adjust to the afternoon am g...           1   \n",
              "2  lael brainard was confirmed this afternoonmigu...           1   \n",
              "3  hrodclintonemailcomfriday march amsbwhoeop rei...           1   \n",
              "4  dear good friendbrbrbri am happy to inform you...           1   \n",
              "\n",
              "   suspicious_words  text_len  \n",
              "0                 1      1294  \n",
              "1                 0       153  \n",
              "2                 0       174  \n",
              "3                 0        79  \n",
              "4                 1      1320  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4bc22d9-059d-471b-a3fd-85e1b13bf357\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>preprocessed_text</th>\n",
              "      <th>money_mark</th>\n",
              "      <th>suspicious_words</th>\n",
              "      <th>text_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>usiness is for the fact that the deceased man ...</td>\n",
              "      <td>usiness is for the fact that the deceased man ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>They are happy to adjust to the afternoon. I a...</td>\n",
              "      <td>they are happy to adjust to the afternoon am g...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Lael Brainard was confirmed 78-19 this afterno...</td>\n",
              "      <td>lael brainard was confirmed this afternoonmigu...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>H &lt;hrod17@clintonemail.com&gt;Friday March 26 201...</td>\n",
              "      <td>hrodclintonemailcomfriday march amsbwhoeop rei...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>n;\"&gt; Dear Good Friend,&lt;br&gt;&lt;br&gt;&lt;br&gt;I am happy t...</td>\n",
              "      <td>dear good friendbrbrbri am happy to inform you...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1320</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4bc22d9-059d-471b-a3fd-85e1b13bf357')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c4bc22d9-059d-471b-a3fd-85e1b13bf357 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c4bc22d9-059d-471b-a3fd-85e1b13bf357');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-090a8437-885d-40bc-9bd6-224e86795844\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-090a8437-885d-40bc-9bd6-224e86795844')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-090a8437-885d-40bc-9bd6-224e86795844 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_data",
              "summary": "{\n  \"name\": \"test_data\",\n  \"rows\": 5964,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5322,\n        \"samples\": [\n          \"Senkaku is the Japanese nameDiayou is the Chinese name (the Diayoutai guesthouse is named after the islands) I've seen reference to both in articles.We say Senkaku.\",\n          \"Yes it is at variance perhaps not surprising. However post is also involved so we will be getting another assessment.\",\n          \"They did.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preprocessed_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5217,\n        \"samples\": [\n          \"just starting had to have little come to with some of our colleagues but folks now on boardfir is up there with them\",\n          \"im on it and will report tomorrow am\",\n          \"bmy random stuff can wait till the morning talked to who is back to really wanting an ambassadorship mark weiner wants to have party for capricia told him wed love it but after the confirmation and we can dosomething nice on th floorvuants to come see privately this week he wants to talk to you about iran before he sees biden at afundraiser when hes in dc this week\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"money_mark\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"suspicious_words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2651,\n        \"min\": 0,\n        \"max\": 60108,\n        \"num_unique_values\": 2208,\n        \"samples\": [\n          3409\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "# We add to the original dataframe two additional indicators (money symbols and suspicious words).\n",
        "money_simbol_list = \"|\".join([\"euro\",\"dollar\",\"pound\",\"€\",\"$\"])\n",
        "suspicious_words = \"|\".join([\"free\",\"cheap\",\"sex\",\"money\",\"account\",\"bank\",\"fund\",\"transfer\",\"transaction\",\"win\",\"deposit\",\"password\"])\n",
        "\n",
        "train_data['money_mark'] = train_data['preprocessed_text'].str.contains(money_simbol_list)*1\n",
        "train_data['suspicious_words'] = train_data['preprocessed_text'].str.contains(suspicious_words)*1\n",
        "train_data['text_len'] = train_data['preprocessed_text'].apply(lambda x: len(x))\n",
        "\n",
        "test_data['money_mark'] = test_data['preprocessed_text'].str.contains(money_simbol_list)*1\n",
        "test_data['suspicious_words'] = test_data['preprocessed_text'].str.contains(suspicious_words)*1\n",
        "test_data['text_len'] = test_data['preprocessed_text'].apply(lambda x: len(x))\n",
        "\n",
        "test_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92hAG0HK4yRm"
      },
      "source": [
        "## How would work the Bag of Words with Count Vectorizer concept?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5XbEXe54yRm",
        "outputId": "1aa24f47-1bf9-42af-f6d4-24b10195f307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of Words Feature Matrix (Training Data):\n",
            "   aac  aaclocated  aae  aag  aaronovitchon  abacha  abachabefore  abachac  \\\n",
            "0    0           0    0    0              0       0             0        0   \n",
            "1    0           0    0    0              0       0             0        0   \n",
            "2    0           0    0    0              0       0             0        0   \n",
            "3    0           0    0    0              0       0             0        0   \n",
            "4    0           0    0    0              0       0             0        0   \n",
            "\n",
            "   abachace  abachaco  ...  zongo  zongothe  zuhair  \\\n",
            "0         0         0  ...      0         0       0   \n",
            "1         0         0  ...      0         0       0   \n",
            "2         0         0  ...      0         0       0   \n",
            "3         0         0  ...      0         0       0   \n",
            "4         0         0  ...      0         0       0   \n",
            "\n",
            "   zulatoebikozulatonetscapeenet  zulatoffffffffffffffffff  zuma  zumac  \\\n",
            "0                              0                         0     0      0   \n",
            "1                              0                         0     0      0   \n",
            "2                              0                         0     0      0   \n",
            "3                              0                         0     1      1   \n",
            "4                              0                         0     0      0   \n",
            "\n",
            "   zumadirector  zumae  zurich  \n",
            "0             0      0       0  \n",
            "1             0      0       0  \n",
            "2             0      0       0  \n",
            "3             0      1       0  \n",
            "4             0      0       0  \n",
            "\n",
            "[5 rows x 21020 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Initialize CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the training set\n",
        "X_train_bow = vectorizer.fit_transform(train_data[\"preprocessed_text\"])\n",
        "\n",
        "# Transform the test set (using the same vocabulary)\n",
        "X_test_bow = vectorizer.transform(test_data[\"preprocessed_text\"])\n",
        "\n",
        "# Convert BoW to a DataFrame for visualization\n",
        "df_train_bow = pd.DataFrame(X_train_bow.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# Show first few rows of transformed dataset\n",
        "print(\"Bag of Words Feature Matrix (Training Data):\")\n",
        "print(df_train_bow.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGgpf7984yRm"
      },
      "source": [
        "## TD-IDF\n",
        "\n",
        "- Load the vectorizer\n",
        "\n",
        "- Vectorize all dataset\n",
        "\n",
        "- print the shape of the vetorized dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3hIebeh4yRm",
        "outputId": "763c1e45-3719-4d89-dc88-cbf5c3aad3f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Feature Count: 1018\n",
            "Test Feature Count: 1018\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english', min_df=10, max_features=3000)\n",
        "\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "print(f\"Train Feature Count: {X_train_tfidf.shape[1]}\")\n",
        "print(f\"Test Feature Count: {X_test_tfidf.shape[1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize training and test sets\n",
        "train_words = set(\" \".join(X_train).split())\n",
        "test_words = set(\" \".join(X_test).split())\n",
        "\n",
        "# Find words that exist in test but not in train\n",
        "new_test_words = test_words - train_words\n",
        "\n",
        "print(f\"Unique words in X_test but not in X_train: {len(new_test_words)}\")\n",
        "print(list(new_test_words)[:20])  # Show sample words\n"
      ],
      "metadata": {
        "id": "6pvLfXVFANuO",
        "outputId": "a93809c4-559d-4759-c8db-6a160359f3eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique words in X_test but not in X_train: 2288\n",
            "['toassist', 'aiash', 'foremostc', 'ifonly', 'chequeget', 'laszczychlstategov', 'diversiondue', 'placedthis', 'weband', 'anexcess', 'blinder', 'theprivate', 'attentioncfirstlyc', 'tocharity', 'shy', 'circlesc', 'itduring', 'wittes', 'notentertain', 'mecwe']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sample X_train Text:\")\n",
        "print(X_train.head())\n",
        "\n",
        "print(\"\\nSample X_test Text:\")\n",
        "print(X_test.head())\n"
      ],
      "metadata": {
        "id": "jnN7uJfO-iGy",
        "outputId": "b3dd546a-12ec-4e95-c7a7-0e7b340dd2e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample X_train Text:\n",
            "29         regard nelson smithkindly reply private email\n",
            "535           able reach oscar supposed send pdb receive\n",
            "695    huma abedin bim checking pat work jack jake re...\n",
            "557                          announced monday cant today\n",
            "836    bank africaagence san pedro bp san pedro cote ...\n",
            "Name: text, dtype: object\n",
            "\n",
            "Sample X_test Text:\n",
            "521    dear sirc wish go offer consider partnerei mre...\n",
            "737    take mind balkan second see great plug global ...\n",
            "740                               pls keep update coming\n",
            "660    christ bethel hospital rue aboboteabidjanivory...\n",
            "411    sbwhoeopfriday february amhre bravo brava issu...\n",
            "Name: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw7uUGio4yRm"
      },
      "source": [
        "## And the Train a Classifier?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X_train Shape: {X_train.shape}\")\n",
        "print(f\"y_train Shape: {y_train.shape}\")"
      ],
      "metadata": {
        "id": "-e3kzMbe9YLM",
        "outputId": "dd717ed1-6a7a-4749-e319-855ad0059d21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train Shape: (800,)\n",
            "y_train Shape: (800,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-ggefvR4yRm",
        "outputId": "22d94ca1-41f3-4992-daf8-8ea66c5464fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.94      0.96       125\n",
            "           1       0.91      0.95      0.93        75\n",
            "\n",
            "    accuracy                           0.94       200\n",
            "   macro avg       0.94      0.95      0.94       200\n",
            "weighted avg       0.95      0.94      0.95       200\n",
            "\n",
            "Accuracy: 0.9450\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Train a Naïve Bayes model\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = nb_model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate model performance\n",
        "print(\"🔹 Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7dLFM6-4yRn"
      },
      "source": [
        "### Extra Task - Implement a SPAM/HAM classifier\n",
        "\n",
        "https://www.kaggle.com/t/b384e34013d54d238490103bc3c360ce\n",
        "\n",
        "The classifier can not be changed!!! It must be the MultinimialNB with default parameters!\n",
        "\n",
        "Your task is to find the **best feature representation**.\n",
        "\n",
        "You can work with teams of two persons (recommended)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WJGESO94yRn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}