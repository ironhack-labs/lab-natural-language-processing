{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denish\\AppData\\Local\\Temp\\ipykernel_37388\\3777615979.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Natural Language Processing\n",
    "### SMS: SPAM or HAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read Data for the Fraudulent Email Kaggle Challenge\n",
    "- Reduce the training set to speead up development. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "## Read Data for the Fraudulent Email Kaggle Challenge\n",
    "data = pd.read_csv(r\"C:\\Users\\Denish\\Desktop\\AI\\Labs\\lab-natural-language-processing\\data\\kg_train.csv\",encoding='latin-1')\n",
    "\n",
    "# Reduce the training set to speed up development. \n",
    "# Modify for final system\n",
    "data = data.head(1000)\n",
    "print(data.shape)\n",
    "data.fillna(\"\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will do.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nora--Cheryl has emailed dozens of memos about...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dear Sir=2FMadam=2C I know that this proposal ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fyi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...      1\n",
       "1                                           Will do.      0\n",
       "2  Nora--Cheryl has emailed dozens of memos about...      0\n",
       "3  Dear Sir=2FMadam=2C I know that this proposal ...      1\n",
       "4                                                fyi      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's divide the training and test set into two partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Original data\n",
    "X = data[['text']]   # Make X a DataFrame with 'text' column\n",
    "y = data['label']\n",
    "\n",
    "# Split the data\n",
    "data_train, data_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Add labels back to train and val\n",
    "data_train = data_train.copy()\n",
    "data_train['label'] = y_train.values\n",
    "\n",
    "data_val = data_val.copy()\n",
    "data_val['label'] = y_val.values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "['needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "print(string.punctuation)\n",
    "print(stopwords.words(\"english\")[100:110])\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "snowball = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we have to clean the html code removing words\n",
    "\n",
    "- First we remove inline JavaScript/CSS\n",
    "- Then we remove html comments. This has to be done before removing regular tags since comments can contain '>' characters\n",
    "- Next we can remove the remaining tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "#First we remove inline JavaScript/CSS\n",
    "import re\n",
    "\n",
    "def remove_html_javascript(text):\n",
    "    # Remove <script> or <style> blocks\n",
    "    text = re.sub(r'<(script|style).*?>.*?</\\1>', '', text, flags=re.DOTALL)\n",
    "    \n",
    "    # Remove HTML comments\n",
    "    text = re.sub(r'<!--.*?-->', '', text, flags=re.DOTALL)\n",
    "    \n",
    "    # Remove remaining HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "data_train['text'] = data_train['text'].apply(remove_html_javascript)\n",
    "data_val['text'] = data_val['text'].apply(remove_html_javascript)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>----------- REGARDS, MR NELSON SMITH.KINDLY RE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>I have not been able to reach oscar this am. W...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>; Huma Abedin B6I'm checking with Pat on the 5...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>I can have it announced here on Monday - can't...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>BANK OF AFRICAAGENCE SAN PEDRO14 BP 1210 S...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "29   ----------- REGARDS, MR NELSON SMITH.KINDLY RE...      1\n",
       "535  I have not been able to reach oscar this am. W...      0\n",
       "695  ; Huma Abedin B6I'm checking with Pat on the 5...      0\n",
       "557  I can have it announced here on Monday - can't...      0\n",
       "836      BANK OF AFRICAAGENCE SAN PEDRO14 BP 1210 S...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove all the special characters\n",
    "    \n",
    "- Remove numbers\n",
    "    \n",
    "- Remove all single characters\n",
    " \n",
    "- Remove single characters from the start\n",
    "\n",
    "- Substitute multiple spaces with single space\n",
    "\n",
    "- Remove prefixed 'b'\n",
    "\n",
    "- Convert to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "import string\n",
    "import re\n",
    "\n",
    "def cleaning_text(text):\n",
    "    # 1. Remove all special characters (keep letters, numbers, and spaces)\n",
    "    text = ''.join(char if char.isalnum() or char.isspace() else ' ' for char in text)\n",
    "\n",
    "    # 2. Remove numbers\n",
    "    text = ''.join(char for char in text if not char.isdigit())\n",
    "\n",
    "    # Split into words to handle single-character words\n",
    "    words = text.split()\n",
    "\n",
    "    # 3. Remove all single-character words\n",
    "    words = [word for word in words if len(word) > 1]\n",
    "\n",
    "    # Join back to string\n",
    "    text = ' '.join(words)\n",
    "\n",
    "    # 4. Remove single character from the beginning of the entire text if present\n",
    "    if len(text) > 0 and len(text[0]) == 1 and text[0].isalpha():\n",
    "        text = text[1:]\n",
    "\n",
    "    # 5. Substitute multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # 6. Remove prefixed 'b' if present (like b'example')\n",
    "    if text.startswith(\"b'\") or text.startswith('b\"'):\n",
    "        text = text[2:-1]\n",
    "\n",
    "    # 7. Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "data_train['text'] = data_train['text'].apply(cleaning_text)\n",
    "data_val['text'] = data_val['text'].apply(cleaning_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>egards mr nelson smith kindly reply me on my p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>ave not been able to reach oscar this am we ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>uma abedin bi checking with pat on the will wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>an have it announced here on monday can today</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>ank of africaagence san pedro bp san pedro cot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "29   egards mr nelson smith kindly reply me on my p...      1\n",
       "535  ave not been able to reach oscar this am we ar...      0\n",
       "695  uma abedin bi checking with pat on the will wo...      0\n",
       "557      an have it announced here on monday can today      0\n",
       "836  ank of africaagence san pedro bp san pedro cot...      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Now let's work on removing stopwords\n",
    "Remove the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "#Remove stop words\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "data_train['text'] = data_train['text'].apply(remove_stopwords)\n",
    "data_val['text'] = data_val['text'].apply(remove_stopwords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tame Your Text with Lemmatization\n",
    "Break sentences into words, then use lemmatization to reduce them to their base form (e.g., \"running\" becomes \"run\"). See how this creates cleaner data for analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your \n",
    "#Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "data_train['text'] = data_train['text'].apply(lemmatize_text)\n",
    "data_val['text'] = data_val['text'].apply(lemmatize_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>egards mr nelson smith kindly reply private em...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>ave able reach oscar supposed send pdb receive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>uma abedin bi checking pat work jack jake rest...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>announced monday today</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>ank africaagence san pedro bp san pedro cote i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "29   egards mr nelson smith kindly reply private em...      1\n",
       "535     ave able reach oscar supposed send pdb receive      0\n",
       "695  uma abedin bi checking pat work jack jake rest...      0\n",
       "557                             announced monday today      0\n",
       "836  ank africaagence san pedro bp san pedro cote i...      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of WordsLet's get the 10 top words in ham and spam messages (**EXPLORATORY DATA ANALYSIS**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ham messages:                                                   text  label\n",
      "535     ave able reach oscar supposed send pdb receive      0\n",
      "695  uma abedin bi checking pat work jack jake rest...      0\n",
      "557                             announced monday today      0\n",
      "824  ear nancy much want meet trying pin schedule e...      0\n",
      "65   ust met fr gudziak come back kyiv visit also j...      0\n",
      "141          word back chinese availability blair fine      0\n",
      "925                                 hen steinberg call      0\n",
      "827                                      ugust hillary      0\n",
      "664  ith permission changing statement spokesman na...      0\n",
      "907  lso ann sending number people include kc honor...      0\n",
      "Number of spam messages:                                                   text  label\n",
      "29   egards mr nelson smith kindly reply private em...      1\n",
      "836  ank africaagence san pedro bp san pedro cote i...      1\n",
      "596  ear friend proposal surprising personal contac...      1\n",
      "165  oneri bank limitedsilver jubilee center cbritt...      1\n",
      "918            asy joy powerful yahoo bookmark toolbar      1\n",
      "495  rom amr ecollince addoattn ai need urgent assi...      1\n",
      "655  rom miss maria deniseaddress ave rue abidjan c...      1\n",
      "331  ear friend mr phil ipenza provincial manager d...      1\n",
      "249  dear friend dr yetunde bassey bank manager dia...      1\n",
      "708  ompliment contact surprising manner respectful...      1\n"
     ]
    }
   ],
   "source": [
    "#Let's get the 10 top words in ham and spam messages (**EXPLORATORY DATA ANALYSIS**)\n",
    "ham_messages = data_train[data_train['label'] == 0]\n",
    "spam_messages = data_train[data_train['label'] == 1]\n",
    "\n",
    "print(\"Number of ham messages:\", ham_messages[:10])\n",
    "print(\"Number of spam messages:\", spam_messages[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>money_mark</th>\n",
       "      <th>suspicious_words</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>egards mr nelson smith kindly reply private em...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>ave able reach oscar supposed send pdb receive</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>uma abedin bi checking pat work jack jake rest...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>announced monday today</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>ank africaagence san pedro bp san pedro cote i...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label  money_mark  \\\n",
       "29   egards mr nelson smith kindly reply private em...      1           1   \n",
       "535     ave able reach oscar supposed send pdb receive      0           1   \n",
       "695  uma abedin bi checking pat work jack jake rest...      0           1   \n",
       "557                             announced monday today      0           1   \n",
       "836  ank africaagence san pedro bp san pedro cote i...      1           1   \n",
       "\n",
       "     suspicious_words  text_len  \n",
       "29                  0        79  \n",
       "535                 0        46  \n",
       "695                 0        78  \n",
       "557                 0        22  \n",
       "836                 1      1050  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We add to the original dataframe two additional indicators (money symbols and suspicious words).\n",
    "money_simbol_list = \"|\".join([\"euro\",\"dollar\",\"pound\",\"€\",r\"\\$\"])\n",
    "suspicious_words = \"|\".join([\"free\",\"cheap\",\"sex\",\"money\",\"account\",\"bank\",\"fund\",\"transfer\",\"transaction\",\"win\",\"deposit\",\"password\"])\n",
    "\n",
    "data_train['money_mark'] = data_train['text'].str.contains(money_simbol_list)*1\n",
    "data_train['suspicious_words'] = data_train['text'].str.contains(suspicious_words)*1\n",
    "data_train['text_len'] = data_train['text'].apply(lambda x: len(x)) \n",
    "\n",
    "data_val['money_mark'] = data_val['text'].str.contains(money_simbol_list)*1\n",
    "data_val['suspicious_words'] = data_val['text'].str.contains(suspicious_words)*1\n",
    "data_val['text_len'] = data_val['text'].apply(lambda x: len(x)) \n",
    "\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How would work the Bag of Words with Count Vectorizer concept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab</th>\n",
       "      <th>abacha</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abidjan</th>\n",
       "      <th>able</th>\n",
       "      <th>abroad</th>\n",
       "      <th>accept</th>\n",
       "      <th>acceptance</th>\n",
       "      <th>access</th>\n",
       "      <th>accord</th>\n",
       "      <th>...</th>\n",
       "      <th>writing</th>\n",
       "      <th>www</th>\n",
       "      <th>yahoo</th>\n",
       "      <th>year</th>\n",
       "      <th>yet</th>\n",
       "      <th>yi</th>\n",
       "      <th>york</th>\n",
       "      <th>yr</th>\n",
       "      <th>zimbabwe</th>\n",
       "      <th>â½</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ab  abacha  abandoned  abidjan  able  abroad  accept  acceptance  access  \\\n",
       "0   0       0          0        0     0       0       0           0       0   \n",
       "1   0       0          0        0     1       0       0           0       0   \n",
       "2   0       0          0        0     0       0       0           0       0   \n",
       "3   0       0          0        0     0       0       0           0       0   \n",
       "4   0       0          0        0     0       0       0           0       0   \n",
       "\n",
       "   accord  ...  writing  www  yahoo  year  yet  yi  york  yr  zimbabwe  â½  \n",
       "0       0  ...        0    0      1     0    0   0     0   0         0   0  \n",
       "1       0  ...        0    0      0     0    0   0     0   0         0   0  \n",
       "2       0  ...        0    0      0     0    0   0     0   0         0   0  \n",
       "3       0  ...        0    0      0     0    0   0     0   0         0   0  \n",
       "4       0  ...        0    0      3     1    0   0     0   0         0   0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code\n",
    "#Bag of Words with count vectroizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Initialize CountVectorizer        \n",
    "count_vectorizer = CountVectorizer(max_features=1000)  # Limit to 1000 features for speed\n",
    "# Fit and transform the training data\n",
    "X_train_counts = count_vectorizer.fit_transform(data_train['text'])\n",
    "# Transform the validation data\n",
    "X_val_counts = count_vectorizer.transform(data_val['text'])\n",
    "# Convert to DataFrame for better visualization\n",
    "X_train_counts_df = pd.DataFrame(X_train_counts.toarray(), columns=count_vectorizer.get_feature_names_out())\n",
    "X_train_counts_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "- Load the vectorizer\n",
    "\n",
    "- Vectorize all dataset\n",
    "\n",
    "- print the shape of the vetorized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset TF-IDF shape: (800, 20275)\n",
      "Validation dataset TF-IDF shape: (200, 20275)\n"
     ]
    }
   ],
   "source": [
    "# Your code\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 1. Load the vectorizer and fit on training data (to learn vocabulary and IDF)\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# 2. Vectorize training data\n",
    "X_train_tfidf = vectorizer.fit_transform(data_train['text'])\n",
    "\n",
    "# 3. Vectorize validation data (use transform, NOT fit_transform)\n",
    "X_val_tfidf = vectorizer.transform(data_val['text'])\n",
    "\n",
    "# 4. Print shapes\n",
    "print(\"Train dataset TF-IDF shape:\", X_train_tfidf.shape)\n",
    "print(\"Validation dataset TF-IDF shape:\", X_val_tfidf.shape)\n",
    "# 5. Convert to DataFrame for better visualization\n",
    "X_train_tfidf_df = pd.DataFrame(X_train_tfidf.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And the Train a Classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.96\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       125\n",
      "           1       1.00      0.89      0.94        75\n",
      "\n",
      "    accuracy                           0.96       200\n",
      "   macro avg       0.97      0.95      0.96       200\n",
      "weighted avg       0.96      0.96      0.96       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming your labels are in data_train['label'] and data_val['label']\n",
    "y_train = data_train['label']\n",
    "y_val = data_val['label']\n",
    "\n",
    "# Initialize the classifier\n",
    "clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the classifier on TF-IDF features\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = clf.predict(X_val_tfidf)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Task - Implement a SPAM/HAM classifier\n",
    "\n",
    "https://www.kaggle.com/t/b384e34013d54d238490103bc3c360ce\n",
    "\n",
    "The classifier can not be changed!!! It must be the MultinimialNB with default parameters!\n",
    "\n",
    "Your task is to **find the most relevant features**.\n",
    "\n",
    "For example, you can test the following options and check which of them performs better:\n",
    "- Using \"Bag of Words\" only\n",
    "- Using \"TF-IDF\" only\n",
    "- Bag of Words + extra flags (money_mark, suspicious_words, text_len)\n",
    "- TF-IDF + extra flags\n",
    "\n",
    "\n",
    "You can work with teams of two persons (recommended)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(data_train['text'])\n",
    "X_val_counts = vectorizer.transform(data_val['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 20275), (200, 20275))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.toarray().shape, X_val_counts.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2), min_df=2, max_df=0.9, stop_words='english')\n",
    "X_train_counts = vectorizer.fit_transform(data_train['text'])\n",
    "X_val_counts = vectorizer.transform(data_val['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# Vectorized text\n",
    "X_train_vec = vectorizer.fit_transform(data_train['text'])\n",
    "X_val_vec = vectorizer.transform(data_val['text'])\n",
    "\n",
    "# Numeric features as sparse matrix\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "numeric_features_train = data_train[['money_mark', 'suspicious_words', 'text_len']].values\n",
    "numeric_features_val = data_val[['money_mark', 'suspicious_words', 'text_len']].values\n",
    "\n",
    "# Convert numeric features to sparse and hstack\n",
    "X_train_final = hstack([X_train_vec, sparse.csr_matrix(numeric_features_train)])\n",
    "X_val_final = hstack([X_val_vec, sparse.csr_matrix(numeric_features_val)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.97\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       125\n",
      "           1       0.94      0.99      0.96        75\n",
      "\n",
      "    accuracy                           0.97       200\n",
      "   macro avg       0.96      0.97      0.97       200\n",
      "weighted avg       0.97      0.97      0.97       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the classifier with default params\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train_final, y_train)\n",
    "\n",
    "# Predict on validation data\n",
    "y_pred = clf.predict(X_val_final)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
