{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Natural Language Processing\n",
    "### SMS: SPAM or HAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read Data for the Fraudulent Email Kaggle Challenge\n",
    "- Reduce the training set to speead up development. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read Data for the Fraudulent Email Kaggle Challenge\n",
    "data = pd.read_csv(\"../data/kg_train.csv\",encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Reduce the training set to speed up development. \n",
    "# Modify for final system\n",
    "data = data.head(1000)\n",
    "print(data.shape)\n",
    "data.fillna(\"\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../data/kg_test.csv\",encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's divide the training and test set into two partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_tuples = list(data.itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cl = NaiveBayesClassifier(data_tuples)\n",
    "# cl.show_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "['needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "print(string.punctuation)\n",
    "print(stopwords.words(\"english\")[100:110])\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "snowball = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we have to clean the html code removing words\n",
    "\n",
    "- First we remove inline JavaScript/CSS\n",
    "- Then we remove html comments. This has to be done before removing regular tags since comments can contain '>' characters\n",
    "- Next we can remove the remaining tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove all the special characters\n",
    "    \n",
    "- Remove numbers\n",
    "    \n",
    "- Remove all single characters\n",
    " \n",
    "- Remove single characters from the start\n",
    "\n",
    "- Substitute multiple spaces with single space\n",
    "\n",
    "- Remove prefixed 'b'\n",
    "\n",
    "- Convert to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # 1. Remove inline JavaScript/CSS\n",
    "    text = re.sub(r'<script.*?>.*?</script>', '', text, flags=re.DOTALL | re.IGNORECASE)\n",
    "    text = re.sub(r'<style.*?>.*?</style>', '', text, flags=re.DOTALL | re.IGNORECASE)\n",
    "    \n",
    "    # 2. Remove HTML comments\n",
    "    text = re.sub(r'<!--.*?-->', '', text, flags=re.DOTALL)\n",
    "    \n",
    "    # 3. Remove remaining HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    \n",
    "    # 4. Remove special characters (punctuation)\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", '', text)\n",
    "    \n",
    "    # 5. Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # 6. Remove all single characters (isolated)\n",
    "    text = re.sub(r'\\b[a-zA-Z]\\b', '', text)\n",
    "    \n",
    "    # 7. Substitute multiple spaces with single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # 8. Remove prefixed 'b' (like from byte literals: b'text')\n",
    "    text = re.sub(r\"^b\\s+\", '', text)\n",
    "    \n",
    "    # 9. Convert to lowercase\n",
    "    text = text.lower().strip()\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to the dataframe\n",
    "data['clean_text'] = data['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      dear sir strictly private business proposal am...\n",
       "1                                                will do\n",
       "2      noracheryl has emailed dozens of memos about h...\n",
       "3      dear sirfmadamc know that this proposal might ...\n",
       "4                                                    fyi\n",
       "                             ...                        \n",
       "995    so whats the latest it sounds contradictory an...\n",
       "996    transfer of million pounds to youraccountmy na...\n",
       "997    barb will call to explain are you back in the ...\n",
       "998       yang on travelnot free tonitemay work tomorrow\n",
       "999    sbwhoeopsunday february pmhshaunh just talked ...\n",
       "Name: clean_text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Now let's work on removing stopwords\n",
    "Remove the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, stopfile = 'english'):\n",
    "    badwords = stopwords.words(stopfile)\n",
    "    words = word_tokenize(text)  # tokenize & lowercase\n",
    "    filtered_words = [w for w in words if w not in badwords]\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "# Apply to the dataframe\n",
    "data['no_stopwords'] = data['clean_text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tame Your Text with Lemmatization\n",
    "Break sentences into words, then use lemmatization to reduce them to their base form (e.g., \"running\" becomes \"run\"). See how this creates cleaner data for analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...</td>\n",
       "      <td>1</td>\n",
       "      <td>dear sir strictly private business proposal am...</td>\n",
       "      <td>[dear, sir, strictly, private, business, propo...</td>\n",
       "      <td>[dear, sir, strictly, private, business, propo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will do.</td>\n",
       "      <td>0</td>\n",
       "      <td>will do</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nora--Cheryl has emailed dozens of memos about...</td>\n",
       "      <td>0</td>\n",
       "      <td>noracheryl has emailed dozens of memos about h...</td>\n",
       "      <td>[noracheryl, emailed, dozens, memos, haiti, we...</td>\n",
       "      <td>[noracheryl, email, dozen, memo, haiti, weeken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dear Sir=2FMadam=2C I know that this proposal ...</td>\n",
       "      <td>1</td>\n",
       "      <td>dear sirfmadamc know that this proposal might ...</td>\n",
       "      <td>[dear, sirfmadamc, know, proposal, might, surp...</td>\n",
       "      <td>[dear, sirfmadamc, know, proposal, might, surp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fyi</td>\n",
       "      <td>0</td>\n",
       "      <td>fyi</td>\n",
       "      <td>[fyi]</td>\n",
       "      <td>[fyi]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...      1   \n",
       "1                                           Will do.      0   \n",
       "2  Nora--Cheryl has emailed dozens of memos about...      0   \n",
       "3  Dear Sir=2FMadam=2C I know that this proposal ...      1   \n",
       "4                                                fyi      0   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  dear sir strictly private business proposal am...   \n",
       "1                                            will do   \n",
       "2  noracheryl has emailed dozens of memos about h...   \n",
       "3  dear sirfmadamc know that this proposal might ...   \n",
       "4                                                fyi   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  [dear, sir, strictly, private, business, propo...   \n",
       "1                                                 []   \n",
       "2  [noracheryl, emailed, dozens, memos, haiti, we...   \n",
       "3  [dear, sirfmadamc, know, proposal, might, surp...   \n",
       "4                                              [fyi]   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  [dear, sir, strictly, private, business, propo...  \n",
       "1                                                 []  \n",
       "2  [noracheryl, email, dozen, memo, haiti, weeken...  \n",
       "3  [dear, sirfmadamc, know, proposal, might, surp...  \n",
       "4                                              [fyi]  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# unfortunately pos_tag and lemmatize use different codes for parts of speech\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper() # gets first letter of POS categorization\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN) # get returns second argument if first key does not exist\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer_with_pos(row):\n",
    "  return [lemmatizer.lemmatize(word,get_wordnet_pos(word)) for word in row['no_stopwords']]\n",
    "\n",
    "data['lemmatized'] = data.apply(lemmatizer_with_pos, axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of Words\n",
    "Let's get the 10 top words in ham and spam messages (**EXPLORATORY DATA ANALYSIS**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>aac</th>\n",
       "      <th>aaclocated</th>\n",
       "      <th>aae</th>\n",
       "      <th>aag</th>\n",
       "      <th>...</th>\n",
       "      <th>â½t</th>\n",
       "      <th>â½ta</th>\n",
       "      <th>â½te</th>\n",
       "      <th>â½tica</th>\n",
       "      <th>â½to</th>\n",
       "      <th>â½trangers</th>\n",
       "      <th>â½v</th>\n",
       "      <th>â½x</th>\n",
       "      <th>â½xã</th>\n",
       "      <th>â½ã</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...</td>\n",
       "      <td>1</td>\n",
       "      <td>dear sir strictly private business proposal am...</td>\n",
       "      <td>[dear, sir, strictly, private, business, propo...</td>\n",
       "      <td>[dear, sir, strictly, private, business, propo...</td>\n",
       "      <td>dear sir strictly private business proposal mi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will do.</td>\n",
       "      <td>0</td>\n",
       "      <td>will do</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nora--Cheryl has emailed dozens of memos about...</td>\n",
       "      <td>0</td>\n",
       "      <td>noracheryl has emailed dozens of memos about h...</td>\n",
       "      <td>[noracheryl, emailed, dozens, memos, haiti, we...</td>\n",
       "      <td>[noracheryl, email, dozen, memo, haiti, weeken...</td>\n",
       "      <td>noracheryl email dozen memo haiti weekend plea...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dear Sir=2FMadam=2C I know that this proposal ...</td>\n",
       "      <td>1</td>\n",
       "      <td>dear sirfmadamc know that this proposal might ...</td>\n",
       "      <td>[dear, sirfmadamc, know, proposal, might, surp...</td>\n",
       "      <td>[dear, sirfmadamc, know, proposal, might, surp...</td>\n",
       "      <td>dear sirfmadamc know proposal might surprise e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fyi</td>\n",
       "      <td>0</td>\n",
       "      <td>fyi</td>\n",
       "      <td>[fyi]</td>\n",
       "      <td>[fyi]</td>\n",
       "      <td>fyi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37097 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...      1   \n",
       "1                                           Will do.      0   \n",
       "2  Nora--Cheryl has emailed dozens of memos about...      0   \n",
       "3  Dear Sir=2FMadam=2C I know that this proposal ...      1   \n",
       "4                                                fyi      0   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  dear sir strictly private business proposal am...   \n",
       "1                                            will do   \n",
       "2  noracheryl has emailed dozens of memos about h...   \n",
       "3  dear sirfmadamc know that this proposal might ...   \n",
       "4                                                fyi   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  [dear, sir, strictly, private, business, propo...   \n",
       "1                                                 []   \n",
       "2  [noracheryl, emailed, dozens, memos, haiti, we...   \n",
       "3  [dear, sirfmadamc, know, proposal, might, surp...   \n",
       "4                                              [fyi]   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  [dear, sir, strictly, private, business, propo...   \n",
       "1                                                 []   \n",
       "2  [noracheryl, email, dozen, memo, haiti, weeken...   \n",
       "3  [dear, sirfmadamc, know, proposal, might, surp...   \n",
       "4                                              [fyi]   \n",
       "\n",
       "                                   preprocessed_text  aac  aaclocated  aae  \\\n",
       "0  dear sir strictly private business proposal mi...    0           0    0   \n",
       "1                                                       0           0    0   \n",
       "2  noracheryl email dozen memo haiti weekend plea...    0           0    0   \n",
       "3  dear sirfmadamc know proposal might surprise e...    0           0    0   \n",
       "4                                                fyi    0           0    0   \n",
       "\n",
       "   aag  ...  â½t  â½ta  â½te  â½tica  â½to  â½trangers  â½v  â½x  â½xã  â½ã  \n",
       "0    0  ...    0     0     0       0     0           0    0    0     0    0  \n",
       "1    0  ...    0     0     0       0     0           0    0    0     0    0  \n",
       "2    0  ...    0     0     0       0     0           0    0    0     0    0  \n",
       "3    0  ...    0     0     0       0     0           0    0    0     0    0  \n",
       "4    0  ...    0     0     0       0     0           0    0    0     0    0  \n",
       "\n",
       "[5 rows x 37097 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def re_blob(row):\n",
    "  return \" \".join(row['lemmatized'])\n",
    "\n",
    "data['preprocessed_text'] = data.apply(re_blob,axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the clean_text column\n",
    "X = vectorizer.fit_transform(data[\"preprocessed_text\"])\n",
    "\n",
    "# Get the feature names (the words)\n",
    "bow_columns = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert to a DataFrame if you want to inspect\n",
    "bow_df = pd.DataFrame(X.toarray(), columns=bow_columns)\n",
    "\n",
    "# Optionally join with your original df\n",
    "df_bow = pd.concat([data, bow_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>aac</th>\n",
       "      <th>aaclocated</th>\n",
       "      <th>aae</th>\n",
       "      <th>aag</th>\n",
       "      <th>...</th>\n",
       "      <th>â½te</th>\n",
       "      <th>â½tica</th>\n",
       "      <th>â½to</th>\n",
       "      <th>â½trangers</th>\n",
       "      <th>â½v</th>\n",
       "      <th>â½x</th>\n",
       "      <th>â½xã</th>\n",
       "      <th>â½ã</th>\n",
       "      <th>suspicious_words</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...</td>\n",
       "      <td>1</td>\n",
       "      <td>dear sir strictly private business proposal am...</td>\n",
       "      <td>[dear, sir, strictly, private, business, propo...</td>\n",
       "      <td>[dear, sir, strictly, private, business, propo...</td>\n",
       "      <td>dear sir strictly private business proposal mi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will do.</td>\n",
       "      <td>0</td>\n",
       "      <td>will do</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nora--Cheryl has emailed dozens of memos about...</td>\n",
       "      <td>0</td>\n",
       "      <td>noracheryl has emailed dozens of memos about h...</td>\n",
       "      <td>[noracheryl, emailed, dozens, memos, haiti, we...</td>\n",
       "      <td>[noracheryl, email, dozen, memo, haiti, weeken...</td>\n",
       "      <td>noracheryl email dozen memo haiti weekend plea...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dear Sir=2FMadam=2C I know that this proposal ...</td>\n",
       "      <td>1</td>\n",
       "      <td>dear sirfmadamc know that this proposal might ...</td>\n",
       "      <td>[dear, sirfmadamc, know, proposal, might, surp...</td>\n",
       "      <td>[dear, sirfmadamc, know, proposal, might, surp...</td>\n",
       "      <td>dear sirfmadamc know proposal might surprise e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fyi</td>\n",
       "      <td>0</td>\n",
       "      <td>fyi</td>\n",
       "      <td>[fyi]</td>\n",
       "      <td>[fyi]</td>\n",
       "      <td>fyi</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55644 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...      1   \n",
       "1                                           Will do.      0   \n",
       "2  Nora--Cheryl has emailed dozens of memos about...      0   \n",
       "3  Dear Sir=2FMadam=2C I know that this proposal ...      1   \n",
       "4                                                fyi      0   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  dear sir strictly private business proposal am...   \n",
       "1                                            will do   \n",
       "2  noracheryl has emailed dozens of memos about h...   \n",
       "3  dear sirfmadamc know that this proposal might ...   \n",
       "4                                                fyi   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  [dear, sir, strictly, private, business, propo...   \n",
       "1                                                 []   \n",
       "2  [noracheryl, emailed, dozens, memos, haiti, we...   \n",
       "3  [dear, sirfmadamc, know, proposal, might, surp...   \n",
       "4                                              [fyi]   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  [dear, sir, strictly, private, business, propo...   \n",
       "1                                                 []   \n",
       "2  [noracheryl, email, dozen, memo, haiti, weeken...   \n",
       "3  [dear, sirfmadamc, know, proposal, might, surp...   \n",
       "4                                              [fyi]   \n",
       "\n",
       "                                   preprocessed_text  aac  aaclocated  aae  \\\n",
       "0  dear sir strictly private business proposal mi...    0           0    0   \n",
       "1                                                       0           0    0   \n",
       "2  noracheryl email dozen memo haiti weekend plea...    0           0    0   \n",
       "3  dear sirfmadamc know proposal might surprise e...    0           0    0   \n",
       "4                                                fyi    0           0    0   \n",
       "\n",
       "   aag  ...  â½te  â½tica  â½to  â½trangers  â½v  â½x  â½xã  â½ã  \\\n",
       "0    0  ...     0       0     0           0    0    0     0    0   \n",
       "1    0  ...     0       0     0           0    0    0     0    0   \n",
       "2    0  ...     0       0     0           0    0    0     0    0   \n",
       "3    0  ...     0       0     0           0    0    0     0    0   \n",
       "4    0  ...     0       0     0           0    0    0     0    0   \n",
       "\n",
       "   suspicious_words  text_len  \n",
       "0                 1      1463  \n",
       "1                 0         0  \n",
       "2                 0       108  \n",
       "3                 1      1353  \n",
       "4                 0         3  \n",
       "\n",
       "[5 rows x 55644 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We add to the original dataframe two additional indicators (money symbols and suspicious words).\n",
    "money_simbol_list = \"|\".join([\"euro\",\"dollar\",\"pound\",\"€\",r\"\\$\"])\n",
    "suspicious_words = \"|\".join([\"free\",\"cheap\",\"sex\",\"money\",\"account\",\"bank\",\"fund\",\"transfer\",\"transaction\",\"win\",\"deposit\",\"password\"])\n",
    "\n",
    "df_bow['money_mark'] = df_bow['preprocessed_text'].str.contains(money_simbol_list)*1\n",
    "df_bow['suspicious_words'] = df_bow['preprocessed_text'].str.contains(suspicious_words)*1\n",
    "df_bow['text_len'] = df_bow['preprocessed_text'].apply(lambda x: len(x)) \n",
    "\n",
    "# df_bow['money_mark'] = df_bow['preprocessed_text'].str.contains(money_simbol_list)*1\n",
    "# df_bow['suspicious_words'] = df_bow['preprocessed_text'].str.contains(suspicious_words)*1\n",
    "# df_bow['text_len'] = df_bow['preprocessed_text'].apply(lambda x: len(x)) \n",
    "\n",
    "df_bow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How would work the Bag of Words with Count Vectorizer concept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "- Load the vectorizer\n",
    "\n",
    "- Vectorize all dataset\n",
    "\n",
    "- print the shape of the vetorized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read Data for the Fraudulent Email Kaggle Challenge\n",
    "df = pd.read_csv(\"../data/kg_train.csv\",encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOC: text\n",
      "[[0.034 0.063 0.    ... 0.    0.    0.   ]]\n",
      "\n",
      "DOC: label\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df = 1)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df.text.to_list())\n",
    "\n",
    "\n",
    "for doc,tf_idf_doc in zip(df,tfidf_matrix.todense()):\n",
    "    print(\"DOC:\", doc)\n",
    "    print(np.around(tf_idf_doc,3)) # El tres define los decimales\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And the Train a Classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Task - Implement a SPAM/HAM classifier\n",
    "\n",
    "https://www.kaggle.com/t/b384e34013d54d238490103bc3c360ce\n",
    "\n",
    "The classifier can not be changed!!! It must be the MultinimialNB with default parameters!\n",
    "\n",
    "Your task is to **find the most relevant features**.\n",
    "\n",
    "For example, you can test the following options and check which of them performs better:\n",
    "- Using \"Bag of Words\" only\n",
    "- Using \"TF-IDF\" only\n",
    "- Bag of Words + extra flags (money_mark, suspicious_words, text_len)\n",
    "- TF-IDF + extra flags\n",
    "\n",
    "\n",
    "You can work with teams of two persons (recommended)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "venv (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
