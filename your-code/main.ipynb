{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dylan\\AppData\\Local\\Temp\\ipykernel_31860\\3777615979.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Natural Language Processing\n",
    "### SMS: SPAM or HAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dylan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read Data for the Fraudulent Email Kaggle Challenge\n",
    "- Reduce the training set to speead up development. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "## Read Data for the Fraudulent Email Kaggle Challenge\n",
    "data_train = pd.read_csv(\"../data/kg_train.csv\",encoding='latin-1')\n",
    "\n",
    "# Reduce the training set to speed up development. \n",
    "# Modify for final system\n",
    "data_train = data_train.head(1000)\n",
    "print(data_train.shape)\n",
    "data_train.fillna(\"\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will do.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nora--Cheryl has emailed dozens of memos about...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dear Sir=2FMadam=2C I know that this proposal ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fyi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...      1\n",
       "1                                           Will do.      0\n",
       "2  Nora--Cheryl has emailed dozens of memos about...      0\n",
       "3  Dear Sir=2FMadam=2C I know that this proposal ...      1\n",
       "4                                                fyi      0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's divide the training and test set into two partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 800\n",
      "Test set size: 200\n"
     ]
    }
   ],
   "source": [
    "# Your code\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(train)}\")\n",
    "print(f\"Test set size: {len(test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "['here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "print(string.punctuation)\n",
    "print(stopwords.words(\"english\")[100:110])\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "snowball = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we have to clean the html code removing words\n",
    "\n",
    "- First we remove inline JavaScript/CSS\n",
    "- Then we remove html comments. This has to be done before removing regular tags since comments can contain '>' characters\n",
    "- Next we can remove the remaining tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label  \\\n",
      "0  DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...      1   \n",
      "1                                           Will do.      0   \n",
      "2  Nora--Cheryl has emailed dozens of memos about...      0   \n",
      "3  Dear Sir=2FMadam=2C I know that this proposal ...      1   \n",
      "4                                                fyi      0   \n",
      "\n",
      "                                      cleaned_column  \n",
      "0  DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...  \n",
      "1                                           Will do.  \n",
      "2  Nora--Cheryl has emailed dozens of memos about...  \n",
      "3  Dear Sir=2FMadam=2C I know that this proposal ...  \n",
      "4                                                fyi  \n"
     ]
    }
   ],
   "source": [
    "# Your code\n",
    "# Function to clean HTML\n",
    "def clean_html(html):\n",
    "    # Step 1: Remove inline JavaScript/CSS\n",
    "    no_js_css = re.sub(r'<(script|style)[^>]*>.*?</\\1>', '', html, flags=re.DOTALL)\n",
    "    # Step 2: Remove HTML comments\n",
    "    no_comments = re.sub(r'<!--.*?-->', '', no_js_css, flags=re.DOTALL)\n",
    "    # Step 3: Remove remaining HTML tags\n",
    "    clean_text = re.sub(r'<[^>]+>', '', no_comments)\n",
    "    # Step 4: Strip excess whitespace\n",
    "    return clean_text.strip()\n",
    "\n",
    "# Apply the cleaning function to the DataFrame column\n",
    "data_train['cleaned_column'] = data_train['text'].apply(clean_html)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(data_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove all the special characters\n",
    "    \n",
    "- Remove numbers\n",
    "    \n",
    "- Remove all single characters\n",
    " \n",
    "- Remove single characters from the start\n",
    "\n",
    "- Substitute multiple spaces with single space\n",
    "\n",
    "- Remove prefixed 'b'\n",
    "\n",
    "- Convert to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label  \\\n",
      "0  DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...      1   \n",
      "1                                           Will do.      0   \n",
      "2  Nora--Cheryl has emailed dozens of memos about...      0   \n",
      "3  Dear Sir=2FMadam=2C I know that this proposal ...      1   \n",
      "4                                                fyi      0   \n",
      "\n",
      "                                      cleaned_column  \n",
      "0  dear sir strictly private business proposal am...  \n",
      "1                                            will do  \n",
      "2  noracheryl has emailed dozens of memos about h...  \n",
      "3  dear sirfmadamc know that this proposal might ...  \n",
      "4                                                fyi  \n"
     ]
    }
   ],
   "source": [
    "# Your code\n",
    "# Function to clean HTML and process text\n",
    "def clean_html_and_text(html):\n",
    "    # Step 1: Remove inline JavaScript/CSS\n",
    "    no_js_css = re.sub(r'<(script|style)[^>]*>.*?</\\1>', '', html, flags=re.DOTALL)\n",
    "    # Step 2: Remove HTML comments\n",
    "    no_comments = re.sub(r'<!--.*?-->', '', no_js_css, flags=re.DOTALL)\n",
    "    # Step 3: Remove remaining HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', no_comments)\n",
    "    # Step 4: Strip excess whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Additional cleaning steps:\n",
    "    # Remove all special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove all single characters\n",
    "    text = re.sub(r'\\b[a-zA-Z]\\b', '', text)\n",
    "    # Remove single characters from the start\n",
    "    text = re.sub(r'^[a-zA-Z]\\s+', '', text)\n",
    "    # Substitute multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Remove prefixed 'b' (if present, for bytes-like objects)\n",
    "    text = re.sub(r'^b\\s+', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the DataFrame column\n",
    "data_train['cleaned_column'] = data_train['text'].apply(clean_html_and_text)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(data_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Now let's work on removing stopwords\n",
    "Remove the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label  \\\n",
      "0  DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...      1   \n",
      "1                                           Will do.      0   \n",
      "2  Nora--Cheryl has emailed dozens of memos about...      0   \n",
      "3  Dear Sir=2FMadam=2C I know that this proposal ...      1   \n",
      "4                                                fyi      0   \n",
      "\n",
      "                                      cleaned_column  \n",
      "0  dear sir strictly private business proposal am...  \n",
      "1                                            will do  \n",
      "2  noracheryl has emailed dozens of memos about h...  \n",
      "3  dear sirfmadamc know that this proposal might ...  \n",
      "4                                                fyi  \n"
     ]
    }
   ],
   "source": [
    "# Your code\n",
    "# List of stopwords to remove\n",
    "stopwords = {'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each'}\n",
    "\n",
    "# Function to clean HTML and process text\n",
    "def clean_html_and_text(html):\n",
    "    # Step 1: Remove inline JavaScript/CSS\n",
    "    no_js_css = re.sub(r'<(script|style)[^>]*>.*?</\\1>', '', html, flags=re.DOTALL)\n",
    "    # Step 2: Remove HTML comments\n",
    "    no_comments = re.sub(r'<!--.*?-->', '', no_js_css, flags=re.DOTALL)\n",
    "    # Step 3: Remove remaining HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', no_comments)\n",
    "    # Step 4: Strip excess whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Additional cleaning steps:\n",
    "    # Remove all special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove all single characters\n",
    "    text = re.sub(r'\\b[a-zA-Z]\\b', '', text)\n",
    "    # Remove single characters from the start\n",
    "    text = re.sub(r'^[a-zA-Z]\\s+', '', text)\n",
    "    # Substitute multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Remove prefixed 'b'\n",
    "    text = re.sub(r'^b\\s+', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove stopwords\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the DataFrame column\n",
    "data_train['cleaned_column'] = data_train['text'].apply(clean_html_and_text)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(data_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tame Your Text with Lemmatization\n",
    "Break sentences into words, then use lemmatization to reduce them to their base form (e.g., \"running\" becomes \"run\"). See how this creates cleaner data for analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\dylan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dylan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dylan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\dylan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure NLTK resources are downloaded\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label  \\\n",
      "0  DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...      1   \n",
      "1                                           Will do.      0   \n",
      "2  Nora--Cheryl has emailed dozens of memos about...      0   \n",
      "3  Dear Sir=2FMadam=2C I know that this proposal ...      1   \n",
      "4                                                fyi      0   \n",
      "\n",
      "                                      cleaned_column  \n",
      "0  [dear, sir, strictly, private, business, propo...  \n",
      "1                                         [will, do]  \n",
      "2  [noracheryl, ha, emailed, dozen, of, memo, abo...  \n",
      "3  [dear, sirfmadamc, know, that, this, proposal,...  \n",
      "4                                              [fyi]  \n"
     ]
    }
   ],
   "source": [
    "# Your code\n",
    "# List of stopwords to remove\n",
    "stopwords = {'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each'}\n",
    "\n",
    "# Initialize WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to clean HTML and process text\n",
    "def clean_html_and_text(html):\n",
    "    # Step 1: Remove inline JavaScript/CSS\n",
    "    no_js_css = re.sub(r'<(script|style)[^>]*>.*?</\\1>', '', html, flags=re.DOTALL)\n",
    "    # Step 2: Remove HTML comments\n",
    "    no_comments = re.sub(r'<!--.*?-->', '', no_js_css, flags=re.DOTALL)\n",
    "    # Step 3: Remove remaining HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', no_comments)\n",
    "    # Step 4: Strip excess whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Additional cleaning steps:\n",
    "    # Remove all special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove all single characters\n",
    "    text = re.sub(r'\\b[a-zA-Z]\\b', '', text)\n",
    "    # Remove single characters from the start\n",
    "    text = re.sub(r'^[a-zA-Z]\\s+', '', text)\n",
    "    # Substitute multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Remove prefixed 'b'\n",
    "    text = re.sub(r'^b\\s+', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize text into words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    \n",
    "    # Lemmatize each word\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    # Return the lemmatized words as a list\n",
    "    return lemmatized_words\n",
    "\n",
    "# Apply the cleaning function to the DataFrame column\n",
    "data_train['cleaned_column'] = data_train['text'].apply(clean_html_and_text)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(data_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of Words\n",
    "Let's get the 10 top words in ham and spam messages (**EXPLORATORY DATA ANALYSIS**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words in ham messages:\n",
      "the: 1725\n",
      "to: 1058\n",
      "and: 819\n",
      "a: 816\n",
      "of: 792\n",
      "in: 589\n",
      "that: 393\n",
      "is: 382\n",
      "for: 367\n",
      "it: 319\n",
      "\n",
      "Top 10 words in spam messages:\n",
      "the: 6847\n",
      "to: 5528\n",
      "of: 4909\n",
      "a: 3991\n",
      "and: 3918\n",
      "in: 3202\n",
      "i: 2896\n",
      "this: 2573\n",
      "my: 2047\n",
      "for: 1994\n"
     ]
    }
   ],
   "source": [
    "# Your code\n",
    "# Stopwords to remove\n",
    "stopwords = {'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'you', 'your', 'me', 'are'}\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to clean and preprocess text\n",
    "def clean_and_tokenize(text):\n",
    "    # Remove special characters and convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text).lower()\n",
    "    # Tokenize\n",
    "    words = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    # Lemmatize words\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return words\n",
    "\n",
    "# Apply cleaning and tokenization\n",
    "data_train['cleaned_message'] = data_train['text'].apply(clean_and_tokenize)\n",
    "\n",
    "# Separate ham and spam messages\n",
    "ham_words = [word for message in data_train[data_train['label'] == 0]['cleaned_message'] for word in message]\n",
    "spam_words = [word for message in data_train[data_train['label'] == 1]['cleaned_message'] for word in message]\n",
    "\n",
    "# Count word frequencies\n",
    "ham_word_counts = Counter(ham_words)\n",
    "spam_word_counts = Counter(spam_words)\n",
    "\n",
    "# Get the top 10 words for ham and spam\n",
    "top_ham_words = ham_word_counts.most_common(10)\n",
    "top_spam_words = spam_word_counts.most_common(10)\n",
    "\n",
    "# Display the results\n",
    "print(\"Top 10 words in ham messages:\")\n",
    "for word, count in top_ham_words:\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "print(\"\\nTop 10 words in spam messages:\")\n",
    "for word, count in top_spam_words:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_column</th>\n",
       "      <th>cleaned_message</th>\n",
       "      <th>money_mark</th>\n",
       "      <th>suspicious_words</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...</td>\n",
       "      <td>1</td>\n",
       "      <td>[dear, sir, strictly, private, business, propo...</td>\n",
       "      <td>[dear, sir, strictly, a, private, business, pr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will do.</td>\n",
       "      <td>0</td>\n",
       "      <td>[will, do]</td>\n",
       "      <td>[will, do]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nora--Cheryl has emailed dozens of memos about...</td>\n",
       "      <td>0</td>\n",
       "      <td>[noracheryl, ha, emailed, dozen, of, memo, abo...</td>\n",
       "      <td>[noracheryl, ha, emailed, dozen, of, memo, abo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dear Sir=2FMadam=2C I know that this proposal ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[dear, sirfmadamc, know, that, this, proposal,...</td>\n",
       "      <td>[dear, sirfmadamc, i, know, that, this, propos...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fyi</td>\n",
       "      <td>0</td>\n",
       "      <td>[fyi]</td>\n",
       "      <td>[fyi]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...      1   \n",
       "1                                           Will do.      0   \n",
       "2  Nora--Cheryl has emailed dozens of memos about...      0   \n",
       "3  Dear Sir=2FMadam=2C I know that this proposal ...      1   \n",
       "4                                                fyi      0   \n",
       "\n",
       "                                      cleaned_column  \\\n",
       "0  [dear, sir, strictly, private, business, propo...   \n",
       "1                                         [will, do]   \n",
       "2  [noracheryl, ha, emailed, dozen, of, memo, abo...   \n",
       "3  [dear, sirfmadamc, know, that, this, proposal,...   \n",
       "4                                              [fyi]   \n",
       "\n",
       "                                     cleaned_message  money_mark  \\\n",
       "0  [dear, sir, strictly, a, private, business, pr...         NaN   \n",
       "1                                         [will, do]         NaN   \n",
       "2  [noracheryl, ha, emailed, dozen, of, memo, abo...         NaN   \n",
       "3  [dear, sirfmadamc, i, know, that, this, propos...         NaN   \n",
       "4                                              [fyi]         NaN   \n",
       "\n",
       "   suspicious_words  text_len  \n",
       "0               NaN       374  \n",
       "1               NaN         2  \n",
       "2               NaN        37  \n",
       "3               NaN       330  \n",
       "4               NaN         1  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We add to the original dataframe two additional indicators (money symbols and suspicious words).\n",
    "money_simbol_list = \"|\".join([\"euro\",\"dollar\",\"pound\",\"€\",r\"\\$\"])\n",
    "suspicious_words = \"|\".join([\"free\",\"cheap\",\"sex\",\"money\",\"account\",\"bank\",\"fund\",\"transfer\",\"transaction\",\"win\",\"deposit\",\"password\"])\n",
    "\n",
    "data_train['money_mark'] = data_train['cleaned_column'].str.contains(money_simbol_list)*1\n",
    "data_train['suspicious_words'] = data_train['cleaned_column'].str.contains(suspicious_words)*1\n",
    "data_train['text_len'] = data_train['cleaned_column'].apply(lambda x: len(x)) \n",
    "\n",
    "'''data_val['money_mark'] = data_val['cleaned_column'].str.contains(money_simbol_list)*1\n",
    "data_val['suspicious_words'] = data_val['cleaned_column'].str.contains(suspicious_words)*1\n",
    "data_val['text_len'] = data_val['cleaned_column'].apply(lambda x: len(x)) \n",
    "'''\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How would work the Bag of Words with Count Vectorizer concept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['aac' 'aaclocated' 'aae' ... 'zumadirector' 'zumae' 'zurich']\n",
      "\n",
      "Bag of Words Matrix:\n",
      "     aac  aaclocated  aae  aag  aaronovitchon  abacha  abachabefore  abachac  \\\n",
      "0      0           0    0    0              0       0             0        0   \n",
      "1      0           0    0    0              0       0             0        0   \n",
      "2      0           0    0    0              0       0             0        0   \n",
      "3      0           0    0    0              0       0             0        0   \n",
      "4      0           0    0    0              0       0             0        0   \n",
      "..   ...         ...  ...  ...            ...     ...           ...      ...   \n",
      "995    0           0    0    0              0       0             0        0   \n",
      "996    0           0    0    0              0       0             0        0   \n",
      "997    0           0    0    0              0       0             0        0   \n",
      "998    0           0    0    0              0       0             0        0   \n",
      "999    0           0    0    0              0       0             0        0   \n",
      "\n",
      "     abachace  abachaco  ...  zongo  zongothe  zuhair  \\\n",
      "0           0         0  ...      0         0       0   \n",
      "1           0         0  ...      0         0       0   \n",
      "2           0         0  ...      0         0       0   \n",
      "3           0         0  ...      0         0       0   \n",
      "4           0         0  ...      0         0       0   \n",
      "..        ...       ...  ...    ...       ...     ...   \n",
      "995         0         0  ...      0         0       0   \n",
      "996         0         0  ...      0         0       0   \n",
      "997         0         0  ...      0         0       0   \n",
      "998         0         0  ...      0         0       0   \n",
      "999         0         0  ...      0         0       0   \n",
      "\n",
      "     zulatoebikozulatonetscapeenet  zulatoffffffffffffffffff  zuma  zumac  \\\n",
      "0                                0                         0     0      0   \n",
      "1                                0                         0     0      0   \n",
      "2                                0                         0     0      0   \n",
      "3                                0                         0     1      1   \n",
      "4                                0                         0     0      0   \n",
      "..                             ...                       ...   ...    ...   \n",
      "995                              0                         0     0      0   \n",
      "996                              0                         0     0      0   \n",
      "997                              0                         0     0      0   \n",
      "998                              0                         0     0      0   \n",
      "999                              0                         0     0      0   \n",
      "\n",
      "     zumadirector  zumae  zurich  \n",
      "0               0      0       0  \n",
      "1               0      0       0  \n",
      "2               0      0       0  \n",
      "3               0      1       0  \n",
      "4               0      0       0  \n",
      "..            ...    ...     ...  \n",
      "995             0      0       0  \n",
      "996             0      0       0  \n",
      "997             0      0       0  \n",
      "998             0      0       0  \n",
      "999             0      0       0  \n",
      "\n",
      "[1000 rows x 19454 columns]\n"
     ]
    }
   ],
   "source": [
    "# Your code\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the text data\n",
    "bow_matrix = vectorizer.fit_transform(data_train['cleaned_column'])\n",
    "\n",
    "# Get feature names (vocabulary)\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert the sparse matrix to a dense DataFrame for better visualization\n",
    "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=vocabulary)\n",
    "\n",
    "print(\"Vocabulary:\", vocabulary)\n",
    "print(\"\\nBag of Words Matrix:\")\n",
    "print(bow_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "- Load the vectorizer\n",
    "\n",
    "- Vectorize all dataset\n",
    "\n",
    "- print the shape of the vetorized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the TF-IDF vectorized dataset: (1000, 19454)\n",
      "\n",
      "Feature Names (Vocabulary):\n",
      "['aac' 'aaclocated' 'aae' ... 'zumadirector' 'zumae' 'zurich']\n",
      "\n",
      "TF-IDF Matrix:\n",
      "     aac  aaclocated  aae  aag  aaronovitchon  abacha  abachabefore  abachac  \\\n",
      "0    0.0         0.0  0.0  0.0            0.0     0.0           0.0      0.0   \n",
      "1    0.0         0.0  0.0  0.0            0.0     0.0           0.0      0.0   \n",
      "2    0.0         0.0  0.0  0.0            0.0     0.0           0.0      0.0   \n",
      "3    0.0         0.0  0.0  0.0            0.0     0.0           0.0      0.0   \n",
      "4    0.0         0.0  0.0  0.0            0.0     0.0           0.0      0.0   \n",
      "..   ...         ...  ...  ...            ...     ...           ...      ...   \n",
      "995  0.0         0.0  0.0  0.0            0.0     0.0           0.0      0.0   \n",
      "996  0.0         0.0  0.0  0.0            0.0     0.0           0.0      0.0   \n",
      "997  0.0         0.0  0.0  0.0            0.0     0.0           0.0      0.0   \n",
      "998  0.0         0.0  0.0  0.0            0.0     0.0           0.0      0.0   \n",
      "999  0.0         0.0  0.0  0.0            0.0     0.0           0.0      0.0   \n",
      "\n",
      "     abachace  abachaco  ...  zongo  zongothe  zuhair  \\\n",
      "0         0.0       0.0  ...    0.0       0.0     0.0   \n",
      "1         0.0       0.0  ...    0.0       0.0     0.0   \n",
      "2         0.0       0.0  ...    0.0       0.0     0.0   \n",
      "3         0.0       0.0  ...    0.0       0.0     0.0   \n",
      "4         0.0       0.0  ...    0.0       0.0     0.0   \n",
      "..        ...       ...  ...    ...       ...     ...   \n",
      "995       0.0       0.0  ...    0.0       0.0     0.0   \n",
      "996       0.0       0.0  ...    0.0       0.0     0.0   \n",
      "997       0.0       0.0  ...    0.0       0.0     0.0   \n",
      "998       0.0       0.0  ...    0.0       0.0     0.0   \n",
      "999       0.0       0.0  ...    0.0       0.0     0.0   \n",
      "\n",
      "     zulatoebikozulatonetscapeenet  zulatoffffffffffffffffff      zuma  \\\n",
      "0                              0.0                       0.0  0.000000   \n",
      "1                              0.0                       0.0  0.000000   \n",
      "2                              0.0                       0.0  0.000000   \n",
      "3                              0.0                       0.0  0.072037   \n",
      "4                              0.0                       0.0  0.000000   \n",
      "..                             ...                       ...       ...   \n",
      "995                            0.0                       0.0  0.000000   \n",
      "996                            0.0                       0.0  0.000000   \n",
      "997                            0.0                       0.0  0.000000   \n",
      "998                            0.0                       0.0  0.000000   \n",
      "999                            0.0                       0.0  0.000000   \n",
      "\n",
      "        zumac  zumadirector     zumae  zurich  \n",
      "0    0.000000           0.0  0.000000     0.0  \n",
      "1    0.000000           0.0  0.000000     0.0  \n",
      "2    0.000000           0.0  0.000000     0.0  \n",
      "3    0.082515           0.0  0.082515     0.0  \n",
      "4    0.000000           0.0  0.000000     0.0  \n",
      "..        ...           ...       ...     ...  \n",
      "995  0.000000           0.0  0.000000     0.0  \n",
      "996  0.000000           0.0  0.000000     0.0  \n",
      "997  0.000000           0.0  0.000000     0.0  \n",
      "998  0.000000           0.0  0.000000     0.0  \n",
      "999  0.000000           0.0  0.000000     0.0  \n",
      "\n",
      "[1000 rows x 19454 columns]\n"
     ]
    }
   ],
   "source": [
    "# Your code\n",
    "# Initialize the TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# If the 'message' column contains lists of tokens, join them into strings\n",
    "if isinstance(data_train['cleaned_column'][0], list):\n",
    "    data_train['cleaned_column'] = data_train['cleaned_column'].apply(lambda tokens: ' '.join(tokens))\n",
    "    \n",
    "# Fit and transform the dataset\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data_train['cleaned_column'])\n",
    "\n",
    "# Print the shape of the vectorized dataset\n",
    "print(f\"Shape of the TF-IDF vectorized dataset: {tfidf_matrix.shape}\")\n",
    "\n",
    "# Display the feature names (vocabulary)\n",
    "print(\"\\nFeature Names (Vocabulary):\")\n",
    "print(tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Convert the sparse TF-IDF matrix to a dense DataFrame for better visualization\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "print(\"\\nTF-IDF Matrix:\")\n",
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And the Train a Classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "# Initialize TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Vectorize the dataset\n",
    "X = tfidf_vectorizer.fit_transform(data_train['cleaned_column'])\n",
    "\n",
    "# Target variable (labels)\n",
    "y = data_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 800 documents\n",
      "Test set size: 200 documents\n"
     ]
    }
   ],
   "source": [
    "# Split into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the size of train/test sets\n",
    "print(f\"Train set size: {X_train.shape[0]} documents\")\n",
    "print(f\"Test set size: {X_test.shape[0]} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "# Train the classifier\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8800\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.89       125\n",
      "           1       0.76      0.99      0.86        75\n",
      "\n",
      "    accuracy                           0.88       200\n",
      "   macro avg       0.88      0.90      0.88       200\n",
      "weighted avg       0.91      0.88      0.88       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Task - Implement a SPAM/HAM classifier\n",
    "\n",
    "https://www.kaggle.com/t/b384e34013d54d238490103bc3c360ce\n",
    "\n",
    "The classifier can not be changed!!! It must be the MultinimialNB with default parameters!\n",
    "\n",
    "Your task is to **find the most relevant features**.\n",
    "\n",
    "For example, you can test the following options and check which of them performs better:\n",
    "- Using \"Bag of Words\" only\n",
    "- Using \"TF-IDF\" only\n",
    "- Bag of Words + extra flags (money_mark, suspicious_words, text_len)\n",
    "- TF-IDF + extra flags\n",
    "\n",
    "\n",
    "You can work with teams of two persons (recommended)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
