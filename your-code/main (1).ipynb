{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: IPython in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (9.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from IPython) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from IPython) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from IPython) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from IPython) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from IPython) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from IPython) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from IPython) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from IPython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from IPython) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from IPython) (4.12.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jedi>=0.16->IPython) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->IPython) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from stack_data->IPython) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from stack_data->IPython) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from stack_data->IPython) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\وجدان ناصر\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade IPython "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (5.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\وجدان ناصر\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.6.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.13.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.10.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from beautifulsoup4) (4.12.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\وجدان ناصر\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas scikit-learn beautifulsoup4 matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Natural Language Processing\n",
    "### SMS: SPAM or HAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read Data for the Fraudulent Email Kaggle Challenge\n",
    "- Reduce the training set to speead up development. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (5964, 2)\n",
      "Testing set shape: (5964, 1)\n",
      "                                                text  label\n",
      "0  DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...      1\n",
      "1                                           Will do.      0\n",
      "2  Nora--Cheryl has emailed dozens of memos about...      0\n",
      "3  Dear Sir=2FMadam=2C I know that this proposal ...      1\n",
      "4                                                fyi      0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# تحميل البيانات\n",
    "train_data = pd.read_csv('data/kg_train.csv')\n",
    "test_data = pd.read_csv('data/kg_test.csv')\n",
    "# Print dataset shapes\n",
    "print(\"Training set shape:\", train_data.shape)\n",
    "print(\"Testing set shape:\", test_data.shape)\n",
    "\n",
    "# عرض أول 5 صفوف للتأكد من البيانات\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's divide the training and test set into two partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "\n",
    "# تقسيم بيانات التدريب إلى 80% تدريب و 20% اختبار\n",
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(\n",
    "    X_train_tfidf, train_data['label'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we have to clean the html code removing words\n",
    "\n",
    "- First we remove inline JavaScript/CSS\n",
    "- Then we remove html comments. This has to be done before removing regular tags since comments can contain '>' characters\n",
    "- Next we can remove the remaining tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (4.13.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\وجدان ناصر\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from beautifulsoup4) (4.12.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\وجدان ناصر\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Your code\n",
    "# تنظيف النصوص (إزالة HTML و CSS)\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'<.*?>', '', text)  # إزالة HTML\n",
    "    text = re.sub(r'http\\S+', '', text)  # إزالة الروابط\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # إزالة الأرقام والعلامات\n",
    "    return text.lower()  # تحويل النص إلى حروف صغيرة\n",
    "\n",
    "train_data['cleaned_text'] = train_data['text'].apply(clean_text)\n",
    "test_data['cleaned_text'] = test_data['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove all the special characters\n",
    "    \n",
    "- Remove numbers\n",
    "    \n",
    "- Remove all single characters\n",
    " \n",
    "- Remove single characters from the start\n",
    "\n",
    "- Substitute multiple spaces with single space\n",
    "\n",
    "- Remove prefixed 'b'\n",
    "\n",
    "- Convert to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Now let's work on removing stopwords\n",
    "Remove the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\وجدان\n",
      "[nltk_data]     ناصر/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Your code\n",
    "# إزالة stop words\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "train_data['cleaned_text'] = train_data['cleaned_text'].apply(remove_stopwords)\n",
    "test_data['cleaned_text'] = test_data['cleaned_text'].apply(remove_stopwords)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tame Your Text with Lemmatization\n",
    "Break sentences into words, then use lemmatization to reduce them to their base form (e.g., \"running\" becomes \"run\"). See how this creates cleaner data for analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "# Stemming: تحويل الكلمات إلى جذرها\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_text(text):\n",
    "    return ' '.join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "train_data['cleaned_text'] = train_data['cleaned_text'].apply(stem_text)\n",
    "test_data['cleaned_text'] = test_data['cleaned_text'].apply(stem_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of Words\n",
    "Let's get the 10 top words in ham and spam messages (**EXPLORATORY DATA ANALYSIS**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ham words:\n",
      " Series([], Name: count, dtype: int64)\n",
      "Top 10 spam words:\n",
      " Series([], Name: count, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Your code\n",
    "# اكتشاف أكثر 10 كلمات شيوعًا في ham و spam\n",
    "ham_words = train_data[train_data['label'] == 'ham']['cleaned_text'].str.split().explode().value_counts().head(10)\n",
    "spam_words = train_data[train_data['label'] == 'spam']['cleaned_text'].str.split().explode().value_counts().head(10)\n",
    "\n",
    "print(\"Top 10 ham words:\\n\", ham_words)\n",
    "print(\"Top 10 spam words:\\n\", spam_words)\n",
    "\n",
    "# تحويل النصوص إلى تمثيل عددي (Bag of Words)\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_data['cleaned_text'])\n",
    "X_test = vectorizer.transform(test_data['cleaned_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'money_simbol_list = \"|\".join([\"euro\",\"dollar\",\"pound\",\"€\",\"$\"])\\nsuspicious_words = \"|\".join([\"free\",\"cheap\",\"sex\",\"money\",\"account\",\"bank\",\"fund\",\"transfer\",\"transaction\",\"win\",\"deposit\",\"password\"])\\n\\ndata_train[\\'money_mark\\'] = data_train[\\'preprocessed_text\\'].str.contains(money_simbol_list)*1\\ndata_train[\\'suspicious_words\\'] = data_train[\\'preprocessed_text\\'].str.contains(suspicious_words)*1\\ndata_train[\\'text_len\\'] = data_train[\\'preprocessed_text\\'].apply(lambda x: len(x)) \\n\\ndata_val[\\'money_mark\\'] = data_val[\\'preprocessed_text\\'].str.contains(money_simbol_list)*1\\ndata_val[\\'suspicious_words\\'] = data_val[\\'preprocessed_text\\'].str.contains(suspicious_words)*1\\ndata_val[\\'text_len\\'] = data_val[\\'preprocessed_text\\'].apply(lambda x: len(x)) \\n\\ndata_train.head()'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We add to the original dataframe two additional indicators (money symbols and suspicious words).\n",
    "'''money_simbol_list = \"|\".join([\"euro\",\"dollar\",\"pound\",\"€\",\"$\"])\n",
    "suspicious_words = \"|\".join([\"free\",\"cheap\",\"sex\",\"money\",\"account\",\"bank\",\"fund\",\"transfer\",\"transaction\",\"win\",\"deposit\",\"password\"])\n",
    "\n",
    "data_train['money_mark'] = data_train['preprocessed_text'].str.contains(money_simbol_list)*1\n",
    "data_train['suspicious_words'] = data_train['preprocessed_text'].str.contains(suspicious_words)*1\n",
    "data_train['text_len'] = data_train['preprocessed_text'].apply(lambda x: len(x)) \n",
    "\n",
    "data_val['money_mark'] = data_val['preprocessed_text'].str.contains(money_simbol_list)*1\n",
    "data_val['suspicious_words'] = data_val['preprocessed_text'].str.contains(suspicious_words)*1\n",
    "data_val['text_len'] = data_val['preprocessed_text'].apply(lambda x: len(x)) \n",
    "\n",
    "data_train.head()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How would work the Bag of Words with Count Vectorizer concept?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TD-IDF\n",
    "\n",
    "- Load the vectorizer\n",
    "\n",
    "- Vectorize all dataset\n",
    "\n",
    "- print the shape of the vetorized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "\n",
    "# تحويل إلى TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_data['cleaned_text'])\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_data['cleaned_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And the Train a Classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "\n",
    "# قائمة النماذج التي سيتم تجربتها\n",
    "models = [\n",
    "    ('Naive Bayes', MultinomialNB()),\n",
    "    ('Random Forest', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
    "    ('SVM', SVC(random_state=42)),\n",
    "    ('Logistic Regression', LogisticRegression(random_state=42))\n",
    "]\n",
    "best_model= None\n",
    "best_accuracy=0\n",
    "\n",
    "# استخدام for loop لتدريب واختبار النماذج\n",
    "for model_name, model in models:\n",
    "    print(f\"Training and evaluating {model_name}...\")\n",
    "    \n",
    "    # تدريب النموذج\n",
    "    model.fit(X_train_split, y_train_split)\n",
    "    \n",
    "    # التنبؤ على بيانات اختبار التدريب (20% من بيانات التدريب)\n",
    "    predictions_train = model.predict(X_test_split)\n",
    "    \n",
    "    # تقييم النموذج على بيانات اختبار التدريب\n",
    "    train_accuracy = accuracy_score(y_test_split, predictions_train)\n",
    "    print(f\"{model_name} - Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "    if train_accuracy >best_accuracy:\n",
    "           best_accuracy = train_accuracy\n",
    "           best_model=model\n",
    "    print(\"-\" *50)\n",
    "    if best_model is not None:\n",
    "       print(f\"\\nBest model: {best_model.__class__.__name__} with accuracy: {best_accuracy * 100:.2f}%\")\n",
    "    else:\n",
    "        print(\"\\nNo model was selected. Check the training process.\")\n",
    "    # طباعة أفضل نموذج تم اختياره\n",
    "print(f\"\\nBest model: {best_model._class.name_} with accuracy: {best_accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "# استخدام أفضل نموذج للتنبؤ على بيانات kg_test.csv\n",
    "predictions_test = best_model.predict(X_test_tfidf)\n",
    "\n",
    "# طباعة أول 10 تنبؤات فقط\n",
    "print(\"\\nPredictions for kg_test.csv (first 10 rows):\")\n",
    "print(predictions_test[:10])\n",
    "\n",
    "# حفظ التوقعات في ملف CSV جديد\n",
    "test_data['predicted_label'] = predictions_test\n",
    "test_data[['text', 'predicted_label']].to_csv(\"kg_test_predictions.csv\", index=False)\n",
    "\n",
    "print(\"\\nPredictions saved to kg_test_predictions.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Task - Implement a SPAM/HAM classifier\n",
    "\n",
    "https://www.kaggle.com/t/b384e34013d54d238490103bc3c360ce\n",
    "\n",
    "The classifier can not be changed!!! It must be the MultinimialNB with default parameters!\n",
    "\n",
    "Your task is to find the **best feature representation**.\n",
    "\n",
    "You can work with teams of two persons (recommended)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
